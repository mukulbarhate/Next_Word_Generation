{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "g5Q7X7WUZEdI"
   },
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x8f in position 5868: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m----> 2\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[43mfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m faqs \u001b[38;5;241m=\u001b[39mtext\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\encodings\\cp1252.py:23\u001b[0m, in \u001b[0;36mIncrementalDecoder.decode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcodecs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcharmap_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdecoding_table\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x8f in position 5868: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "with open(\"r.txt\", 'r') as file:\n",
    "    text = file.read()\n",
    "faqs =text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP = 1\n",
    "sentences = [faqs]\n",
    "next_words = []\n",
    "ignored = 0\n",
    "for i in range(0, len(text_in_words) - SEQUENCE_LEN, STEP):\n",
    "    # Only add sequences where no word is in ignored_words\n",
    "    if len(set(text_in_words[i: i+SEQUENCE_LEN+1]).intersection(ignored_words)) == 0:\n",
    "        sentences.append(text_in_words[i: i + SEQUENCE_LEN])\n",
    "        next_words.append(text_in_words[i + SEQUENCE_LEN])\n",
    "    else:\n",
    "        ignored = ignored+1\n",
    "print('Ignored sequences:', ignored)\n",
    "print('Remaining sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "J1D42emD32Ro"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 16:05:46.293226: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-10 16:05:47.763766: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "KhtDxwL_AXFj"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "K8MRFre9AaG9"
   },
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts([faqs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YrpAl3EDAgvh",
    "outputId": "20b6c8b9-f3e3-4d27-8798-6ef90af392b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "810"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "44VahqKdAjr9"
   },
   "outputs": [],
   "source": [
    "input_sequences = []\n",
    "for sentence in faqs.split('\\n'):\n",
    "  tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0]\n",
    "\n",
    "  for i in range(1,len(tokenized_sentence)):\n",
    "    input_sequences.append(tokenized_sentence[:i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UyqwPDzNA5mR",
    "outputId": "5eae38f5-bab0-4c7f-abaa-b736480ef77b",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[49, 221],\n",
       " [49, 221, 222],\n",
       " [49, 221, 222, 113],\n",
       " [49, 221, 222, 113, 223],\n",
       " [49, 221, 222, 113, 223, 114],\n",
       " [49, 221, 222, 113, 223, 114, 40],\n",
       " [160, 372],\n",
       " [160, 372, 373],\n",
       " [160, 372, 373, 114],\n",
       " [160, 372, 373, 114, 40],\n",
       " [160, 372, 373, 114, 40, 70],\n",
       " [160, 372, 373, 114, 40, 70, 25],\n",
       " [160, 372, 373, 114, 40, 70, 25, 1],\n",
       " [160, 372, 373, 114, 40, 70, 25, 1, 29],\n",
       " [14, 1],\n",
       " [14, 1, 5],\n",
       " [14, 1, 5, 374],\n",
       " [14, 1, 5, 374, 16],\n",
       " [14, 1, 5, 374, 16, 24],\n",
       " [7, 10],\n",
       " [7, 10, 6],\n",
       " [7, 10, 6, 115],\n",
       " [7, 10, 6, 115, 26],\n",
       " [7, 10, 6, 115, 26, 4],\n",
       " [7, 10, 6, 115, 26, 4, 375],\n",
       " [7, 10, 6, 115, 26, 4, 375, 161],\n",
       " [71, 1],\n",
       " [71, 1, 30],\n",
       " [71, 1, 30, 376],\n",
       " [71, 1, 30, 376, 13],\n",
       " [71, 1, 30, 376, 13, 116],\n",
       " [71, 1, 30, 376, 13, 116, 33],\n",
       " [71, 1, 30, 376, 13, 116, 33, 2],\n",
       " [71, 1, 30, 376, 13, 116, 33, 2, 24],\n",
       " [15, 117],\n",
       " [15, 117, 224],\n",
       " [15, 117, 224, 225],\n",
       " [15, 117, 224, 225, 162],\n",
       " [15, 117, 224, 225, 162, 118],\n",
       " [7, 87],\n",
       " [7, 87, 377],\n",
       " [7, 87, 377, 1],\n",
       " [7, 87, 377, 1, 71],\n",
       " [7, 87, 377, 1, 71, 55],\n",
       " [7, 87, 377, 1, 71, 55, 24],\n",
       " [7, 87, 377, 1, 71, 55, 24, 16],\n",
       " [7, 87, 377, 1, 71, 55, 24, 16, 33],\n",
       " [7, 87, 377, 1, 71, 55, 24, 16, 33, 161],\n",
       " [7, 88],\n",
       " [7, 88, 37],\n",
       " [7, 88, 37, 226],\n",
       " [7, 88, 37, 226, 21],\n",
       " [7, 88, 37, 226, 21, 162],\n",
       " [7, 88, 37, 226, 21, 162, 56],\n",
       " [15, 72],\n",
       " [15, 72, 17],\n",
       " [15, 72, 17, 163],\n",
       " [15, 72, 17, 163, 164],\n",
       " [15, 72, 17, 163, 164, 26],\n",
       " [15, 72, 17, 163, 164, 26, 33],\n",
       " [15, 72, 17, 163, 164, 26, 33, 23],\n",
       " [15, 72, 17, 163, 164, 26, 33, 23, 1],\n",
       " [15, 72, 17, 163, 164, 26, 33, 23, 1, 165],\n",
       " [15, 72, 17, 163, 164, 26, 33, 23, 1, 165, 27],\n",
       " [15, 72, 17, 163, 164, 26, 33, 23, 1, 165, 27, 119],\n",
       " [31, 1],\n",
       " [31, 1, 10],\n",
       " [31, 1, 10, 27],\n",
       " [31, 1, 10, 27, 166],\n",
       " [31, 1, 10, 27, 166, 5],\n",
       " [31, 1, 10, 27, 166, 5, 378],\n",
       " [31, 1, 10, 27, 166, 5, 378, 5],\n",
       " [31, 1, 10, 27, 166, 5, 378, 5, 4],\n",
       " [31, 1, 10, 27, 166, 5, 378, 5, 4, 379],\n",
       " [31, 1, 10, 27, 166, 5, 378, 5, 4, 379, 227],\n",
       " [15, 120],\n",
       " [15, 120, 2],\n",
       " [15, 120, 2, 380],\n",
       " [15, 120, 2, 380, 381],\n",
       " [15, 120, 2, 380, 381, 16],\n",
       " [15, 120, 2, 380, 381, 16, 32],\n",
       " [15, 120, 2, 380, 381, 16, 32, 228],\n",
       " [15, 120, 2, 380, 381, 16, 32, 228, 27],\n",
       " [15, 120, 2, 380, 381, 16, 32, 228, 27, 121],\n",
       " [15, 167],\n",
       " [15, 167, 382],\n",
       " [15, 167, 382, 6],\n",
       " [15, 167, 382, 6, 168],\n",
       " [15, 167, 382, 6, 168, 17],\n",
       " [15, 167, 382, 6, 168, 17, 57],\n",
       " [15, 167, 382, 6, 168, 17, 57, 31],\n",
       " [15, 167, 382, 6, 168, 17, 57, 31, 1],\n",
       " [15, 167, 382, 6, 168, 17, 57, 31, 1, 10],\n",
       " [15, 167, 382, 6, 168, 17, 57, 31, 1, 10, 27],\n",
       " [15, 167, 382, 6, 168, 17, 57, 31, 1, 10, 27, 89],\n",
       " [15, 167, 382, 6, 168, 17, 57, 31, 1, 10, 27, 89, 35],\n",
       " [15, 167, 382, 6, 168, 17, 57, 31, 1, 10, 27, 89, 35, 229],\n",
       " [15, 117],\n",
       " [15, 117, 6],\n",
       " [15, 117, 6, 122],\n",
       " [15, 117, 6, 122, 50],\n",
       " [15, 117, 6, 122, 50, 383],\n",
       " [15, 117, 6, 122, 50, 383, 384],\n",
       " [15, 117, 6, 122, 50, 383, 384, 16],\n",
       " [15, 117, 6, 122, 50, 383, 384, 16, 230],\n",
       " [15, 117, 6, 122, 50, 383, 384, 16, 230, 231],\n",
       " [15, 117, 6, 122, 50, 383, 384, 16, 230, 231, 70],\n",
       " [15, 117, 6, 122, 50, 383, 384, 16, 230, 231, 70, 31],\n",
       " [15, 117, 6, 122, 50, 383, 384, 16, 230, 231, 70, 31, 1],\n",
       " [15, 117, 6, 122, 50, 383, 384, 16, 230, 231, 70, 31, 1, 232],\n",
       " [15, 117, 6, 122, 50, 383, 384, 16, 230, 231, 70, 31, 1, 232, 12],\n",
       " [15, 117, 6, 122, 50, 383, 384, 16, 230, 231, 70, 31, 1, 232, 12, 50],\n",
       " [15, 117, 6, 122, 50, 383, 384, 16, 230, 231, 70, 31, 1, 232, 12, 50, 385],\n",
       " [15, 233],\n",
       " [15, 233, 386],\n",
       " [15, 233, 386, 16],\n",
       " [15, 233, 386, 16, 4],\n",
       " [15, 233, 386, 16, 4, 387],\n",
       " [15, 233, 386, 16, 4, 387, 18],\n",
       " [15, 233, 386, 16, 4, 387, 18, 58],\n",
       " [15, 233, 386, 16, 4, 387, 18, 58, 388],\n",
       " [15, 233, 386, 16, 4, 387, 18, 58, 388, 7],\n",
       " [15, 233, 386, 16, 4, 387, 18, 58, 388, 7, 23],\n",
       " [15, 233, 386, 16, 4, 387, 18, 58, 388, 7, 23, 31],\n",
       " [15, 233, 386, 16, 4, 387, 18, 58, 388, 7, 23, 31, 2],\n",
       " [15, 233, 386, 16, 4, 387, 18, 58, 388, 7, 23, 31, 2, 232],\n",
       " [15, 233, 386, 16, 4, 387, 18, 58, 388, 7, 23, 31, 2, 232, 389],\n",
       " [15, 233, 386, 16, 4, 387, 18, 58, 388, 7, 23, 31, 2, 232, 389, 390],\n",
       " [7, 10],\n",
       " [7, 10, 6],\n",
       " [7, 10, 6, 234],\n",
       " [7, 10, 6, 234, 16],\n",
       " [7, 10, 6, 234, 16, 4],\n",
       " [7, 10, 6, 234, 16, 4, 227],\n",
       " [7, 10, 6, 234, 16, 4, 227, 391],\n",
       " [7, 10, 6, 234, 16, 4, 227, 391, 18],\n",
       " [7, 10, 6, 234, 16, 4, 227, 391, 18, 58],\n",
       " [7, 10, 6, 234, 16, 4, 227, 391, 18, 58, 27],\n",
       " [7, 10, 6, 234, 16, 4, 227, 391, 18, 58, 27, 123],\n",
       " [7, 10, 6, 234, 16, 4, 227, 391, 18, 58, 27, 123, 7],\n",
       " [7, 10, 6, 234, 16, 4, 227, 391, 18, 58, 27, 123, 7, 23],\n",
       " [7, 10, 6, 234, 16, 4, 227, 391, 18, 58, 27, 123, 7, 23, 392],\n",
       " [15, 72],\n",
       " [15, 72, 17],\n",
       " [15, 72, 17, 393],\n",
       " [15, 72, 17, 393, 73],\n",
       " [15, 72, 17, 393, 73, 17],\n",
       " [15, 72, 17, 393, 73, 17, 124],\n",
       " [15, 72, 17, 393, 73, 17, 124, 235],\n",
       " [15, 72, 17, 393, 73, 17, 124, 235, 25],\n",
       " [15, 72, 17, 393, 73, 17, 124, 235, 25, 58],\n",
       " [15, 72, 17, 393, 73, 17, 124, 235, 25, 58, 27],\n",
       " [15, 72, 17, 393, 73, 17, 124, 235, 25, 58, 27, 90],\n",
       " [15, 72, 17, 393, 73, 17, 124, 235, 25, 58, 27, 90, 5],\n",
       " [15, 72, 17, 393, 73, 17, 124, 235, 25, 58, 27, 90, 5, 394],\n",
       " [15, 72, 17, 393, 73, 17, 124, 235, 25, 58, 27, 90, 5, 394, 73],\n",
       " [15, 125],\n",
       " [15, 125, 26],\n",
       " [15, 125, 26, 236],\n",
       " [15, 125, 26, 236, 5],\n",
       " [15, 125, 26, 236, 5, 237],\n",
       " [15, 125, 26, 236, 5, 237, 395],\n",
       " [15, 125, 26, 236, 5, 237, 395, 23],\n",
       " [15, 125, 26, 236, 5, 237, 395, 23, 1],\n",
       " [15, 125, 26, 236, 5, 237, 395, 23, 1, 91],\n",
       " [15, 125, 26, 236, 5, 237, 395, 23, 1, 91, 37],\n",
       " [15, 125, 26, 236, 5, 237, 395, 23, 1, 91, 37, 169],\n",
       " [15, 125, 26, 236, 5, 237, 395, 23, 1, 91, 37, 169, 21],\n",
       " [15, 125, 26, 236, 5, 237, 395, 23, 1, 91, 37, 169, 21, 4],\n",
       " [15, 125, 26, 236, 5, 237, 395, 23, 1, 91, 37, 169, 21, 4, 238],\n",
       " [15, 125, 26, 236, 5, 237, 395, 23, 1, 91, 37, 169, 21, 4, 238, 239],\n",
       " [15, 117],\n",
       " [15, 117, 396],\n",
       " [15, 117, 396, 240],\n",
       " [15, 117, 396, 240, 397],\n",
       " [15, 117, 396, 240, 397, 31],\n",
       " [15, 117, 396, 240, 397, 31, 1],\n",
       " [15, 117, 396, 240, 397, 31, 1, 10],\n",
       " [15, 117, 396, 240, 397, 31, 1, 10, 27],\n",
       " [15, 117, 396, 240, 397, 31, 1, 10, 27, 240],\n",
       " [15, 117, 396, 240, 397, 31, 1, 10, 27, 240, 166],\n",
       " [15, 117, 396, 240, 397, 31, 1, 10, 27, 240, 166, 35],\n",
       " [15, 117, 396, 240, 397, 31, 1, 10, 27, 240, 166, 35, 119],\n",
       " [15, 72],\n",
       " [15, 72, 17],\n",
       " [15, 72, 17, 398],\n",
       " [15, 72, 17, 398, 399],\n",
       " [15, 72, 17, 398, 399, 90],\n",
       " [15, 72, 17, 398, 399, 90, 23],\n",
       " [15, 72, 17, 398, 399, 90, 23, 1],\n",
       " [15, 72, 17, 398, 399, 90, 23, 1, 55],\n",
       " [15, 72, 17, 398, 399, 90, 23, 1, 55, 24],\n",
       " [15, 72, 17, 398, 399, 90, 23, 1, 55, 24, 16],\n",
       " [15, 72, 17, 398, 399, 90, 23, 1, 55, 24, 16, 400],\n",
       " [15, 72, 17, 398, 399, 90, 23, 1, 55, 24, 16, 400, 170],\n",
       " [15, 72, 17, 398, 399, 90, 23, 1, 55, 24, 16, 400, 170, 401],\n",
       " [7, 10],\n",
       " [7, 10, 6],\n",
       " [7, 10, 6, 241],\n",
       " [7, 10, 6, 241, 118],\n",
       " [7, 10, 6, 241, 118, 126],\n",
       " [7, 10, 6, 241, 118, 126, 402],\n",
       " [7, 10, 6, 241, 118, 126, 402, 32],\n",
       " [7, 10, 6, 241, 118, 126, 402, 32, 74],\n",
       " [7, 10, 6, 241, 118, 126, 402, 32, 74, 403],\n",
       " [7, 10, 6, 241, 118, 126, 402, 32, 74, 403, 23],\n",
       " [7, 10, 6, 241, 118, 126, 402, 32, 74, 403, 23, 7],\n",
       " [7, 10, 6, 241, 118, 126, 402, 32, 74, 403, 23, 7, 127],\n",
       " [7, 10, 6, 241, 118, 126, 402, 32, 74, 403, 23, 7, 127, 2],\n",
       " [7, 10, 6, 241, 118, 126, 402, 32, 74, 403, 23, 7, 127, 2, 1],\n",
       " [7, 10, 6, 241, 118, 126, 402, 32, 74, 403, 23, 7, 127, 2, 1, 26],\n",
       " [7, 10, 6, 241, 118, 126, 402, 32, 74, 403, 23, 7, 127, 2, 1, 26, 20],\n",
       " [15, 120],\n",
       " [15, 120, 16],\n",
       " [15, 120, 16, 404],\n",
       " [15, 120, 16, 404, 405],\n",
       " [15, 120, 16, 404, 405, 406],\n",
       " [15, 120, 16, 404, 405, 406, 31],\n",
       " [15, 120, 16, 404, 405, 406, 31, 1],\n",
       " [15, 120, 16, 404, 405, 406, 31, 1, 10],\n",
       " [15, 120, 16, 404, 405, 406, 31, 1, 10, 27],\n",
       " [15, 120, 16, 404, 405, 406, 31, 1, 10, 27, 121],\n",
       " [15, 120, 16, 404, 405, 406, 31, 1, 10, 27, 121, 5],\n",
       " [15, 120, 16, 404, 405, 406, 31, 1, 10, 27, 121, 5, 407],\n",
       " [15, 120, 16, 404, 405, 406, 31, 1, 10, 27, 121, 5, 407, 32],\n",
       " [15, 120, 16, 404, 405, 406, 31, 1, 10, 27, 121, 5, 407, 32, 408],\n",
       " [15, 120, 16, 404, 405, 406, 31, 1, 10, 27, 121, 5, 407, 32, 408, 128],\n",
       " [15, 72],\n",
       " [15, 72, 17],\n",
       " [15, 72, 17, 171],\n",
       " [15, 72, 17, 171, 6],\n",
       " [15, 72, 17, 171, 6, 409],\n",
       " [15, 72, 17, 171, 6, 409, 35],\n",
       " [15, 72, 17, 171, 6, 409, 35, 410],\n",
       " [15, 72, 17, 171, 6, 409, 35, 410, 411],\n",
       " [15, 72, 17, 171, 6, 409, 35, 410, 411, 2],\n",
       " [15, 72, 17, 171, 6, 409, 35, 410, 411, 2, 32],\n",
       " [15, 72, 17, 171, 6, 409, 35, 410, 411, 2, 32, 57],\n",
       " [15, 72, 17, 171, 6, 409, 35, 410, 411, 2, 32, 57, 9],\n",
       " [15, 72, 17, 171, 6, 409, 35, 410, 411, 2, 32, 57, 9, 129],\n",
       " [15, 72, 17, 171, 6, 409, 35, 410, 411, 2, 32, 57, 9, 129, 23],\n",
       " [15, 72, 17, 171, 6, 409, 35, 410, 411, 2, 32, 57, 9, 129, 23, 1],\n",
       " [15, 72, 17, 171, 6, 409, 35, 410, 411, 2, 32, 57, 9, 129, 23, 1, 165],\n",
       " [15, 72, 17, 171, 6, 409, 35, 410, 411, 2, 32, 57, 9, 129, 23, 1, 165, 27],\n",
       " [15, 59],\n",
       " [15, 59, 92],\n",
       " [15, 59, 92, 51],\n",
       " [15, 59, 92, 51, 168],\n",
       " [15, 59, 92, 51, 168, 412],\n",
       " [15, 59, 92, 51, 168, 412, 2],\n",
       " [15, 59, 92, 51, 168, 412, 2, 242],\n",
       " [15, 59, 92, 51, 168, 412, 2, 242, 130],\n",
       " [15, 59, 92, 51, 168, 412, 2, 242, 130, 243],\n",
       " [15, 59, 92, 51, 168, 412, 2, 242, 130, 243, 23],\n",
       " [15, 59, 92, 51, 168, 412, 2, 242, 130, 243, 23, 1],\n",
       " [15, 59, 92, 51, 168, 412, 2, 242, 130, 243, 23, 1, 91],\n",
       " [15, 59, 92, 51, 168, 412, 2, 242, 130, 243, 23, 1, 91, 37],\n",
       " [15, 59, 92, 51, 168, 412, 2, 242, 130, 243, 23, 1, 91, 37, 168],\n",
       " [15, 59, 92, 51, 168, 412, 2, 242, 130, 243, 23, 1, 91, 37, 168, 413],\n",
       " [15, 414],\n",
       " [15, 414, 26],\n",
       " [15, 414, 26, 33],\n",
       " [15, 414, 26, 33, 18],\n",
       " [15, 414, 26, 33, 18, 58],\n",
       " [15, 414, 26, 33, 18, 58, 6],\n",
       " [15, 414, 26, 33, 18, 58, 6, 123],\n",
       " [15, 414, 26, 33, 18, 58, 6, 123, 7],\n",
       " [15, 414, 26, 33, 18, 58, 6, 123, 7, 23],\n",
       " [15, 414, 26, 33, 18, 58, 6, 123, 7, 23, 415],\n",
       " [15, 414, 26, 33, 18, 58, 6, 123, 7, 23, 415, 20],\n",
       " [15, 414, 26, 33, 18, 58, 6, 123, 7, 23, 415, 20, 93],\n",
       " [15, 414, 26, 33, 18, 58, 6, 123, 7, 23, 415, 20, 93, 32],\n",
       " [15, 414, 26, 33, 18, 58, 6, 123, 7, 23, 415, 20, 93, 32, 228],\n",
       " [15, 414, 26, 33, 18, 58, 6, 123, 7, 23, 415, 20, 93, 32, 228, 35],\n",
       " [15, 414, 26, 33, 18, 58, 6, 123, 7, 23, 415, 20, 93, 32, 228, 35, 73],\n",
       " [7, 10],\n",
       " [7, 10, 6],\n",
       " [7, 10, 6, 115],\n",
       " [7, 10, 6, 115, 26],\n",
       " [7, 10, 6, 115, 26, 4],\n",
       " [7, 10, 6, 115, 26, 4, 45],\n",
       " [7, 10, 6, 115, 26, 4, 45, 244],\n",
       " [7, 10, 6, 115, 26, 4, 45, 244, 23],\n",
       " [7, 10, 6, 115, 26, 4, 45, 244, 23, 3],\n",
       " [7, 10, 6, 115, 26, 4, 45, 244, 23, 3, 131],\n",
       " [7, 10, 6, 115, 26, 4, 45, 244, 23, 3, 131, 416],\n",
       " [7, 10, 6, 115, 26, 4, 45, 244, 23, 3, 131, 416, 20],\n",
       " [7, 10, 6, 115, 26, 4, 45, 244, 23, 3, 131, 416, 20, 132],\n",
       " [15, 72],\n",
       " [15, 72, 17],\n",
       " [15, 72, 17, 163],\n",
       " [15, 72, 17, 163, 26],\n",
       " [15, 72, 17, 163, 26, 12],\n",
       " [15, 72, 17, 163, 26, 12, 73],\n",
       " [15, 72, 17, 163, 26, 12, 73, 417],\n",
       " [15, 72, 17, 163, 26, 12, 73, 417, 71],\n",
       " [15, 72, 17, 163, 26, 12, 73, 417, 71, 1],\n",
       " [15, 72, 17, 163, 26, 12, 73, 417, 71, 1, 172],\n",
       " [15, 72, 17, 163, 26, 12, 73, 417, 71, 1, 172, 24],\n",
       " [15, 72, 17, 163, 26, 12, 73, 417, 71, 1, 172, 24, 164],\n",
       " [15, 72, 17, 163, 26, 12, 73, 417, 71, 1, 172, 24, 164, 26],\n",
       " [15, 72, 17, 163, 26, 12, 73, 417, 71, 1, 172, 24, 164, 26, 12],\n",
       " [15, 72, 17, 163, 26, 12, 73, 417, 71, 1, 172, 24, 164, 26, 12, 46],\n",
       " [15, 167],\n",
       " [15, 167, 418],\n",
       " [15, 167, 418, 6],\n",
       " [15, 167, 418, 6, 45],\n",
       " [15, 167, 418, 6, 45, 23],\n",
       " [15, 167, 418, 6, 45, 23, 1],\n",
       " [15, 167, 418, 6, 45, 23, 1, 419],\n",
       " [15, 167, 418, 6, 45, 23, 1, 419, 24],\n",
       " [15, 167, 418, 6, 45, 23, 1, 419, 24, 21],\n",
       " [15, 167, 418, 6, 45, 23, 1, 419, 24, 21, 4],\n",
       " [15, 167, 418, 6, 45, 23, 1, 419, 24, 21, 4, 173],\n",
       " [15, 167, 418, 6, 45, 23, 1, 419, 24, 21, 4, 173, 8],\n",
       " [15, 167, 418, 6, 45, 23, 1, 419, 24, 21, 4, 173, 8, 420],\n",
       " [7, 10],\n",
       " [7, 10, 6],\n",
       " [7, 10, 6, 421],\n",
       " [7, 10, 6, 421, 26],\n",
       " [7, 10, 6, 421, 26, 4],\n",
       " [7, 10, 6, 421, 26, 4, 422],\n",
       " [7, 10, 6, 421, 26, 4, 422, 174],\n",
       " [7, 10, 6, 421, 26, 4, 422, 174, 23],\n",
       " [7, 10, 6, 421, 26, 4, 422, 174, 23, 3],\n",
       " [7, 10, 6, 421, 26, 4, 422, 174, 23, 3, 60],\n",
       " [7, 10, 6, 421, 26, 4, 422, 174, 23, 3, 60, 20],\n",
       " [15, 245],\n",
       " [15, 245, 5],\n",
       " [15, 245, 5, 90],\n",
       " [15, 245, 5, 90, 2],\n",
       " [15, 245, 5, 90, 2, 423],\n",
       " [15, 245, 5, 90, 2, 423, 32],\n",
       " [15, 245, 5, 90, 2, 423, 32, 128],\n",
       " [15, 245, 5, 90, 2, 423, 32, 128, 424],\n",
       " [15, 245, 5, 90, 2, 423, 32, 128, 424, 9],\n",
       " [15, 245, 5, 90, 2, 423, 32, 128, 424, 9, 425],\n",
       " [15, 245, 5, 90, 2, 423, 32, 128, 424, 9, 425, 23],\n",
       " [15, 245, 5, 90, 2, 423, 32, 128, 424, 9, 425, 23, 1],\n",
       " [15, 245, 5, 90, 2, 423, 32, 128, 424, 9, 425, 23, 1, 165],\n",
       " [15, 245, 5, 90, 2, 423, 32, 128, 424, 9, 425, 23, 1, 165, 27],\n",
       " [15, 245, 5, 90, 2, 423, 32, 128, 424, 9, 425, 23, 1, 165, 27, 230],\n",
       " [15, 245, 5, 90, 2, 423, 32, 128, 424, 9, 425, 23, 1, 165, 27, 230, 231],\n",
       " [15, 245, 5, 90, 2, 423, 32, 128, 424, 9, 425, 23, 1, 165, 27, 230, 231, 35],\n",
       " [15,\n",
       "  245,\n",
       "  5,\n",
       "  90,\n",
       "  2,\n",
       "  423,\n",
       "  32,\n",
       "  128,\n",
       "  424,\n",
       "  9,\n",
       "  425,\n",
       "  23,\n",
       "  1,\n",
       "  165,\n",
       "  27,\n",
       "  230,\n",
       "  231,\n",
       "  35,\n",
       "  246],\n",
       " [15, 117],\n",
       " [15, 117, 224],\n",
       " [15, 117, 224, 426],\n",
       " [15, 117, 224, 426, 4],\n",
       " [15, 117, 224, 426, 4, 45],\n",
       " [15, 117, 224, 426, 4, 45, 247],\n",
       " [15, 117, 224, 426, 4, 45, 247, 427],\n",
       " [15, 117, 224, 426, 4, 45, 247, 427, 23],\n",
       " [15, 117, 224, 426, 4, 45, 247, 427, 23, 1],\n",
       " [15, 117, 224, 426, 4, 45, 247, 427, 23, 1, 55],\n",
       " [15, 117, 224, 426, 4, 45, 247, 427, 23, 1, 55, 24],\n",
       " [15, 117, 224, 426, 4, 45, 247, 427, 23, 1, 55, 24, 428],\n",
       " [15, 72],\n",
       " [15, 72, 17],\n",
       " [15, 72, 17, 236],\n",
       " [15, 72, 17, 236, 5],\n",
       " [15, 72, 17, 236, 5, 429],\n",
       " [15, 72, 17, 236, 5, 429, 23],\n",
       " [15, 72, 17, 236, 5, 429, 23, 1],\n",
       " [15, 72, 17, 236, 5, 429, 23, 1, 91],\n",
       " [15, 72, 17, 236, 5, 429, 23, 1, 91, 37],\n",
       " [15, 72, 17, 236, 5, 429, 23, 1, 91, 37, 169],\n",
       " [15, 72, 17, 236, 5, 429, 23, 1, 91, 37, 169, 21],\n",
       " [15, 72, 17, 236, 5, 429, 23, 1, 91, 37, 169, 21, 4],\n",
       " [15, 72, 17, 236, 5, 429, 23, 1, 91, 37, 169, 21, 4, 238],\n",
       " [15, 72, 17, 236, 5, 429, 23, 1, 91, 37, 169, 21, 4, 238, 239],\n",
       " [14, 1],\n",
       " [14, 1, 5],\n",
       " [14, 1, 5, 12],\n",
       " [14, 1, 5, 12, 133],\n",
       " [14, 1, 5, 12, 133, 21],\n",
       " [14, 1, 5, 12, 133, 21, 32],\n",
       " [14, 1, 5, 12, 133, 21, 32, 161],\n",
       " [14, 1, 5, 12, 133, 21, 32, 161, 31],\n",
       " [14, 1, 5, 12, 133, 21, 32, 161, 31, 1],\n",
       " [14, 1, 5, 12, 133, 21, 32, 161, 31, 1, 10],\n",
       " [14, 1, 5, 12, 133, 21, 32, 161, 31, 1, 10, 27],\n",
       " [14, 1, 5, 12, 133, 21, 32, 161, 31, 1, 10, 27, 248],\n",
       " [14, 1, 5, 12, 133, 21, 32, 161, 31, 1, 10, 27, 248, 5],\n",
       " [14, 1, 5, 12, 133, 21, 32, 161, 31, 1, 10, 27, 248, 5, 249],\n",
       " [15, 120],\n",
       " [15, 120, 16],\n",
       " [15, 120, 16, 6],\n",
       " [15, 120, 16, 6, 430],\n",
       " [15, 120, 16, 6, 430, 175],\n",
       " [15, 120, 16, 6, 430, 175, 9],\n",
       " [15, 120, 16, 6, 430, 175, 9, 4],\n",
       " [15, 120, 16, 6, 430, 175, 9, 4, 45],\n",
       " [15, 120, 16, 6, 430, 175, 9, 4, 45, 23],\n",
       " [15, 120, 16, 6, 430, 175, 9, 4, 45, 23, 1],\n",
       " [15, 120, 16, 6, 430, 175, 9, 4, 45, 23, 1, 91],\n",
       " [15, 120, 16, 6, 430, 175, 9, 4, 45, 23, 1, 91, 431],\n",
       " [15, 120, 16, 6, 430, 175, 9, 4, 45, 23, 1, 91, 431, 119],\n",
       " [15, 120, 16, 6, 430, 175, 9, 4, 45, 23, 1, 91, 431, 119, 35],\n",
       " [15, 120, 16, 6, 430, 175, 9, 4, 45, 23, 1, 91, 431, 119, 35, 134],\n",
       " [15, 250],\n",
       " [15, 250, 2],\n",
       " [15, 250, 2, 242],\n",
       " [15, 250, 2, 242, 237],\n",
       " [15, 250, 2, 242, 237, 251],\n",
       " [15, 250, 2, 242, 237, 251, 432],\n",
       " [15, 250, 2, 242, 237, 251, 432, 23],\n",
       " [15, 250, 2, 242, 237, 251, 432, 23, 1],\n",
       " [15, 250, 2, 242, 237, 251, 432, 23, 1, 433],\n",
       " [15, 250, 2, 242, 237, 251, 432, 23, 1, 433, 121],\n",
       " [15, 250, 2, 242, 237, 251, 432, 23, 1, 433, 121, 21],\n",
       " [15, 250, 2, 242, 237, 251, 432, 23, 1, 433, 121, 21, 434],\n",
       " [15, 250, 2, 242, 237, 251, 432, 23, 1, 433, 121, 21, 434, 252],\n",
       " [15, 250, 2, 242, 237, 251, 432, 23, 1, 433, 121, 21, 434, 252, 8],\n",
       " [15, 250, 2, 242, 237, 251, 432, 23, 1, 433, 121, 21, 434, 252, 8, 435],\n",
       " [15, 167],\n",
       " [15, 167, 436],\n",
       " [15, 167, 436, 32],\n",
       " [15, 167, 436, 32, 437],\n",
       " [15, 167, 436, 32, 437, 23],\n",
       " [15, 167, 436, 32, 437, 23, 3],\n",
       " [15, 167, 436, 32, 437, 23, 3, 60],\n",
       " [15, 167, 436, 32, 437, 23, 3, 60, 4],\n",
       " [15, 167, 436, 32, 437, 23, 3, 60, 4, 173],\n",
       " [15, 167, 436, 32, 437, 23, 3, 60, 4, 173, 8],\n",
       " [15, 167, 436, 32, 437, 23, 3, 60, 4, 173, 8, 438],\n",
       " [7, 10],\n",
       " [7, 10, 6],\n",
       " [7, 10, 6, 234],\n",
       " [7, 10, 6, 234, 16],\n",
       " [7, 10, 6, 234, 16, 6],\n",
       " [7, 10, 6, 234, 16, 6, 439],\n",
       " [7, 10, 6, 234, 16, 6, 439, 440],\n",
       " [7, 10, 6, 234, 16, 6, 439, 440, 5],\n",
       " [7, 10, 6, 234, 16, 6, 439, 440, 5, 6],\n",
       " [7, 10, 6, 234, 16, 6, 439, 440, 5, 6, 441],\n",
       " [7, 10, 6, 234, 16, 6, 439, 440, 5, 6, 441, 23],\n",
       " [7, 10, 6, 234, 16, 6, 439, 440, 5, 6, 441, 23, 1],\n",
       " [7, 10, 6, 234, 16, 6, 439, 440, 5, 6, 441, 23, 1, 55],\n",
       " [7, 10, 6, 234, 16, 6, 439, 440, 5, 6, 441, 23, 1, 55, 34],\n",
       " [7, 10, 6, 234, 16, 6, 439, 440, 5, 6, 441, 23, 1, 55, 34, 442],\n",
       " [7, 10, 6, 234, 16, 6, 439, 440, 5, 6, 441, 23, 1, 55, 34, 442, 20],\n",
       " [14, 1],\n",
       " [14, 1, 5],\n",
       " [14, 1, 5, 52],\n",
       " [14, 1, 5, 52, 6],\n",
       " [14, 1, 5, 52, 6, 253],\n",
       " [14, 1, 5, 52, 6, 253, 8],\n",
       " [14, 1, 5, 52, 6, 253, 8, 176],\n",
       " [14, 1, 5, 52, 6, 253, 8, 176, 443],\n",
       " [7, 135],\n",
       " [7, 135, 12],\n",
       " [7, 135, 12, 136],\n",
       " [7, 135, 12, 136, 2],\n",
       " [7, 135, 12, 136, 2, 12],\n",
       " [7, 135, 12, 136, 2, 12, 254],\n",
       " [7, 135, 12, 136, 2, 12, 254, 75],\n",
       " [14, 1],\n",
       " [14, 1, 5],\n",
       " [14, 1, 5, 444],\n",
       " [14, 1, 5, 444, 24],\n",
       " [14, 1, 5, 444, 24, 2],\n",
       " [14, 1, 5, 444, 24, 2, 76],\n",
       " [14, 1, 5, 444, 24, 2, 76, 445],\n",
       " [14, 1, 5, 444, 24, 2, 76, 445, 8],\n",
       " [14, 1, 5, 444, 24, 2, 76, 445, 8, 446],\n",
       " [12, 447],\n",
       " [12, 447, 5],\n",
       " [12, 447, 5, 448],\n",
       " [12, 447, 5, 448, 18],\n",
       " [12, 447, 5, 448, 18, 449],\n",
       " [7, 77],\n",
       " [7, 77, 255],\n",
       " [7, 77, 255, 2],\n",
       " [7, 77, 255, 2, 10],\n",
       " [7, 77, 255, 2, 10, 1],\n",
       " [7, 77, 255, 2, 10, 1, 78],\n",
       " [7, 77, 255, 2, 10, 1, 78, 32],\n",
       " [7, 77, 255, 2, 10, 1, 78, 32, 450],\n",
       " [15, 256],\n",
       " [15, 256, 5],\n",
       " [15, 256, 5, 4],\n",
       " [15, 256, 5, 4, 90],\n",
       " [15, 256, 5, 4, 90, 257],\n",
       " [15, 256, 5, 4, 90, 257, 451],\n",
       " [15, 256, 5, 4, 90, 257, 451, 24],\n",
       " [15, 256, 5, 4, 90, 257, 451, 24, 16],\n",
       " [14, 1],\n",
       " [14, 1, 5],\n",
       " [14, 1, 5, 452],\n",
       " [14, 1, 5, 452, 17],\n",
       " [14, 1, 5, 452, 17, 24],\n",
       " [14, 1, 5, 452, 17, 24, 8],\n",
       " [14, 1, 5, 452, 17, 24, 8, 453],\n",
       " [14, 1, 5, 452, 17, 24, 8, 453, 24],\n",
       " [14, 1, 5, 452, 17, 24, 8, 453, 24, 2],\n",
       " [14, 1, 5, 452, 17, 24, 8, 453, 24, 2, 137],\n",
       " [14, 1, 5, 452, 17, 24, 8, 453, 24, 2, 137, 32],\n",
       " [14, 1, 5, 452, 17, 24, 8, 453, 24, 2, 137, 32, 454],\n",
       " [14, 1, 5, 452, 17, 24, 8, 453, 24, 2, 137, 32, 454, 170],\n",
       " [7, 455],\n",
       " [7, 455, 12],\n",
       " [7, 455, 12, 456],\n",
       " [7, 455, 12, 456, 5],\n",
       " [7, 455, 12, 456, 5, 124],\n",
       " [7, 455, 12, 456, 5, 124, 57],\n",
       " [12, 89],\n",
       " [12, 89, 8],\n",
       " [12, 89, 8, 457],\n",
       " [12, 89, 8, 457, 10],\n",
       " [12, 89, 8, 457, 10, 41],\n",
       " [12, 89, 8, 457, 10, 41, 458],\n",
       " [12, 89, 8, 457, 10, 41, 458, 2],\n",
       " [12, 89, 8, 457, 10, 41, 458, 2, 24],\n",
       " [14, 1],\n",
       " [14, 1, 5],\n",
       " [14, 1, 5, 459],\n",
       " [14, 1, 5, 459, 6],\n",
       " [14, 1, 5, 459, 6, 258],\n",
       " [14, 1, 5, 459, 6, 258, 259],\n",
       " [14, 1, 5, 459, 6, 258, 259, 21],\n",
       " [14, 1, 5, 459, 6, 258, 259, 21, 32],\n",
       " [14, 1, 5, 459, 6, 258, 259, 21, 32, 260],\n",
       " [14, 1, 5, 459, 6, 258, 259, 21, 32, 260, 8],\n",
       " [14, 1, 5, 459, 6, 258, 259, 21, 32, 260, 8, 32],\n",
       " [14, 1, 5, 459, 6, 258, 259, 21, 32, 260, 8, 32, 261],\n",
       " [61, 460],\n",
       " [61, 460, 20],\n",
       " [61, 460, 20, 461],\n",
       " [138, 50],\n",
       " [138, 50, 262],\n",
       " [138, 50, 262, 62],\n",
       " [138, 50, 262, 62, 51],\n",
       " [138, 50, 262, 62, 51, 10],\n",
       " [138, 50, 262, 62, 51, 10, 1],\n",
       " [138, 50, 262, 62, 51, 10, 1, 41],\n",
       " [138, 50, 262, 62, 51, 10, 1, 41, 139],\n",
       " [138, 50, 262, 62, 51, 10, 1, 41, 139, 2],\n",
       " [94, 63],\n",
       " [94, 63, 16],\n",
       " [94, 63, 16, 1],\n",
       " [42, 462],\n",
       " [42, 462, 463],\n",
       " [42, 462, 463, 43],\n",
       " [42, 462, 463, 43, 16],\n",
       " [42, 462, 463, 43, 16, 1],\n",
       " [3, 64],\n",
       " [3, 64, 95],\n",
       " [3, 64, 95, 464],\n",
       " [3, 64, 95, 464, 139],\n",
       " [3, 64, 95, 464, 139, 164],\n",
       " [3, 64, 95, 464, 139, 164, 465],\n",
       " [177, 1],\n",
       " [177, 1, 263],\n",
       " [177, 1, 263, 26],\n",
       " [177, 1, 263, 26, 140],\n",
       " [177, 1, 263, 26, 140, 47],\n",
       " [177, 1, 263, 26, 140, 47, 466],\n",
       " [177, 1, 263, 26, 140, 47, 466, 264],\n",
       " [7, 467],\n",
       " [7, 467, 141],\n",
       " [7, 467, 141, 39],\n",
       " [7, 467, 141, 39, 468],\n",
       " [7, 467, 141, 39, 468, 265],\n",
       " [7, 467, 141, 39, 468, 265, 469],\n",
       " [7, 467, 141, 39, 468, 265, 469, 50],\n",
       " [7, 467, 141, 39, 468, 265, 469, 50, 470],\n",
       " [10, 1],\n",
       " [10, 1, 471],\n",
       " [10, 1, 471, 27],\n",
       " [10, 1, 471, 27, 49],\n",
       " [10, 1, 471, 27, 49, 472],\n",
       " [10, 1, 471, 27, 49, 472, 266],\n",
       " [7, 142],\n",
       " [7, 142, 267],\n",
       " [7, 142, 267, 473],\n",
       " [7, 142, 267, 473, 268],\n",
       " [7, 142, 267, 473, 268, 269],\n",
       " [7, 142, 267, 473, 268, 269, 20],\n",
       " [7, 142, 267, 473, 268, 269, 20, 87],\n",
       " [7, 142, 267, 473, 268, 269, 20, 87, 474],\n",
       " [31, 1],\n",
       " [31, 1, 10],\n",
       " [31, 1, 10, 27],\n",
       " [31, 1, 10, 27, 229],\n",
       " [31, 1, 10, 27, 229, 5],\n",
       " [31, 1, 10, 27, 229, 5, 475],\n",
       " [31, 1, 10, 27, 229, 5, 475, 476],\n",
       " [7, 88],\n",
       " [7, 88, 270],\n",
       " [7, 88, 270, 63],\n",
       " [7, 88, 270, 63, 2],\n",
       " [7, 88, 270, 63, 2, 477],\n",
       " [7, 88, 270, 63, 2, 477, 478],\n",
       " [79, 51],\n",
       " [79, 51, 25],\n",
       " [79, 51, 25, 12],\n",
       " [79, 51, 25, 12, 178],\n",
       " [79, 51, 25, 12, 178, 5],\n",
       " [79, 51, 25, 12, 178, 5, 4],\n",
       " [79, 51, 25, 12, 178, 5, 4, 479],\n",
       " [7, 87],\n",
       " [7, 87, 125],\n",
       " [7, 87, 125, 3],\n",
       " [7, 87, 125, 3, 71],\n",
       " [7, 87, 125, 3, 71, 131],\n",
       " [7, 87, 125, 3, 71, 131, 480],\n",
       " [7, 87, 125, 3, 71, 131, 480, 35],\n",
       " [7, 87, 125, 3, 71, 131, 480, 35, 271],\n",
       " [7, 87, 125, 3, 71, 131, 480, 35, 271, 481],\n",
       " [7, 87, 125, 3, 71, 131, 480, 35, 271, 481, 28],\n",
       " [7, 87, 125, 3, 71, 131, 480, 35, 271, 481, 28, 63],\n",
       " [7, 87, 125, 3, 71, 131, 480, 35, 271, 481, 28, 63, 482],\n",
       " [15, 483],\n",
       " [15, 483, 5],\n",
       " [15, 483, 5, 484],\n",
       " [15, 483, 5, 484, 19],\n",
       " [15, 483, 5, 484, 19, 143],\n",
       " [15, 483, 5, 484, 19, 143, 178],\n",
       " [272, 28],\n",
       " [272, 28, 96],\n",
       " [272, 28, 96, 3],\n",
       " [272, 28, 96, 3, 485],\n",
       " [272, 28, 96, 3, 485, 114],\n",
       " [272, 28, 96, 3, 485, 114, 486],\n",
       " [272, 28, 96, 3, 485, 114, 486, 49],\n",
       " [272, 28, 96, 3, 485, 114, 486, 49, 487],\n",
       " [3, 64],\n",
       " [3, 64, 273],\n",
       " [3, 64, 273, 179],\n",
       " [3, 64, 273, 179, 96],\n",
       " [3, 64, 273, 179, 96, 180],\n",
       " [3, 64, 273, 179, 96, 180, 488],\n",
       " [3, 64, 273, 179, 96, 180, 488, 64],\n",
       " [3, 64, 273, 179, 96, 180, 488, 64, 3],\n",
       " [3, 64, 273, 179, 96, 180, 488, 64, 3, 131],\n",
       " [3, 64, 273, 179, 96, 180, 488, 64, 3, 131, 97],\n",
       " [42, 41],\n",
       " [42, 41, 125],\n",
       " [42, 41, 125, 26],\n",
       " [42, 41, 125, 26, 489],\n",
       " [42, 41, 125, 26, 489, 6],\n",
       " [42, 41, 125, 26, 489, 6, 274],\n",
       " [42, 41, 125, 26, 489, 6, 274, 96],\n",
       " [42, 41, 125, 26, 489, 6, 274, 96, 25],\n",
       " [42, 41, 125, 26, 489, 6, 274, 96, 25, 1],\n",
       " [42, 41, 125, 26, 489, 6, 274, 96, 25, 1, 17],\n",
       " [181, 274],\n",
       " [181, 274, 96],\n",
       " [181, 274, 96, 275],\n",
       " [181, 274, 96, 275, 65],\n",
       " [181, 274, 96, 275, 65, 6],\n",
       " [181, 274, 96, 275, 65, 6, 490],\n",
       " [61, 31],\n",
       " [61, 31, 1],\n",
       " [61, 31, 1, 182],\n",
       " [61, 31, 1, 182, 98],\n",
       " [61, 31, 1, 182, 98, 7],\n",
       " [61, 31, 1, 182, 98, 7, 491],\n",
       " [61, 31, 1, 182, 98, 7, 491, 5],\n",
       " [61, 31, 1, 182, 98, 7, 491, 5, 6],\n",
       " [61, 31, 1, 182, 98, 7, 491, 5, 6, 492],\n",
       " [9, 45],\n",
       " [9, 45, 59],\n",
       " [9, 45, 59, 94],\n",
       " [9, 45, 59, 94, 21],\n",
       " [9, 45, 59, 94, 21, 12],\n",
       " [9, 45, 59, 94, 21, 12, 182],\n",
       " [42, 41],\n",
       " [42, 41, 233],\n",
       " [42, 41, 233, 276],\n",
       " [42, 41, 233, 276, 493],\n",
       " [42, 41, 233, 276, 493, 43],\n",
       " [42, 41, 233, 276, 493, 43, 266],\n",
       " [15, 36],\n",
       " [15, 36, 5],\n",
       " [15, 36, 5, 1],\n",
       " [15, 36, 5, 1, 19],\n",
       " [15, 36, 5, 1, 19, 127],\n",
       " [15, 36, 5, 1, 19, 127, 20],\n",
       " [15, 36, 5, 1, 19, 127, 20, 43],\n",
       " [183, 7],\n",
       " [183, 7, 135],\n",
       " [183, 7, 135, 20],\n",
       " [183, 7, 135, 20, 494],\n",
       " [183, 7, 135, 20, 494, 20],\n",
       " [183, 7, 135, 20, 494, 20, 184],\n",
       " [183, 7, 135, 20, 494, 20, 184, 142],\n",
       " [183, 7, 135, 20, 494, 20, 184, 142, 2],\n",
       " [183, 7, 135, 20, 494, 20, 184, 142, 2, 127],\n",
       " [277, 1],\n",
       " [277, 1, 99],\n",
       " [277, 1, 99, 42],\n",
       " [277, 1, 99, 42, 495],\n",
       " [277, 1, 99, 42, 495, 12],\n",
       " [277, 1, 99, 42, 495, 12, 278],\n",
       " [61, 10],\n",
       " [61, 10, 1],\n",
       " [61, 10, 1, 279],\n",
       " [61, 10, 1, 279, 27],\n",
       " [61, 10, 1, 279, 27, 144],\n",
       " [61, 10, 1, 279, 27, 144, 496],\n",
       " [61, 10, 1, 279, 27, 144, 496, 497],\n",
       " [498, 7],\n",
       " [498, 7, 142],\n",
       " [498, 7, 142, 267],\n",
       " [498, 7, 142, 267, 280],\n",
       " [498, 7, 142, 267, 280, 269],\n",
       " [498, 7, 142, 267, 280, 269, 20],\n",
       " [498, 7, 142, 267, 280, 269, 20, 87],\n",
       " [498, 7, 142, 267, 280, 269, 20, 87, 79],\n",
       " [498, 7, 142, 267, 280, 269, 20, 87, 79, 49],\n",
       " [42, 41],\n",
       " [42, 41, 245],\n",
       " [42, 41, 245, 5],\n",
       " [42, 41, 245, 5, 6],\n",
       " [42, 41, 245, 5, 6, 63],\n",
       " [42, 41, 245, 5, 6, 63, 280],\n",
       " [42, 41, 245, 5, 6, 63, 280, 2],\n",
       " [42, 41, 245, 5, 6, 63, 280, 2, 279],\n",
       " [42, 41, 245, 5, 6, 63, 280, 2, 279, 281],\n",
       " [42, 41, 245, 5, 6, 63, 280, 2, 279, 281, 10],\n",
       " [42, 41, 245, 5, 6, 63, 280, 2, 279, 281, 10, 2],\n",
       " [42, 41, 245, 5, 6, 63, 280, 2, 279, 281, 10, 2, 499],\n",
       " [42, 41, 245, 5, 6, 63, 280, 2, 279, 281, 10, 2, 499, 20],\n",
       " [42, 41, 245, 5, 6, 63, 280, 2, 279, 281, 10, 2, 499, 20, 43],\n",
       " [95, 31],\n",
       " [95, 31, 7],\n",
       " [95, 31, 7, 76],\n",
       " [95, 31, 7, 76, 500],\n",
       " [95, 31, 7, 76, 500, 145],\n",
       " [95, 31, 7, 76, 500, 145, 20],\n",
       " [31, 1],\n",
       " [31, 1, 141],\n",
       " [31, 1, 141, 17],\n",
       " [31, 1, 141, 17, 501],\n",
       " [185, 49],\n",
       " [185, 49, 115],\n",
       " [185, 49, 115, 15],\n",
       " [185, 49, 115, 15, 59],\n",
       " [185, 49, 115, 15, 59, 92],\n",
       " [7, 76],\n",
       " [7, 76, 39],\n",
       " [7, 76, 39, 95],\n",
       " [7, 76, 39, 95, 186],\n",
       " [7, 76, 39, 95, 186, 4],\n",
       " [7, 76, 39, 95, 186, 4, 502],\n",
       " [7, 76, 39, 95, 186, 4, 502, 18],\n",
       " [7, 76, 39, 95, 186, 4, 502, 18, 79],\n",
       " [7, 76, 39, 95, 186, 4, 502, 18, 79, 503],\n",
       " [282, 39],\n",
       " [282, 39, 182],\n",
       " [282, 39, 182, 504],\n",
       " [282, 39, 182, 504, 2],\n",
       " [282, 39, 182, 504, 2, 76],\n",
       " [282, 39, 182, 504, 2, 76, 26],\n",
       " [94, 12],\n",
       " [94, 12, 44],\n",
       " [94, 12, 44, 21],\n",
       " [94, 12, 44, 21, 265],\n",
       " [94, 12, 44, 21, 265, 47],\n",
       " [505, 15],\n",
       " [505, 15, 59],\n",
       " [505, 15, 59, 92],\n",
       " [505, 15, 59, 92, 51],\n",
       " [505, 15, 59, 92, 51, 2],\n",
       " [505, 15, 59, 92, 51, 2, 76],\n",
       " [42, 41],\n",
       " [42, 41, 283],\n",
       " [42, 41, 283, 20],\n",
       " [42, 41, 283, 20, 506],\n",
       " [42, 41, 283, 20, 506, 507],\n",
       " [42, 41, 283, 20, 506, 507, 51],\n",
       " [42, 41, 283, 20, 506, 507, 51, 7],\n",
       " [42, 41, 283, 20, 506, 507, 51, 7, 76],\n",
       " [126, 66],\n",
       " [126, 66, 144],\n",
       " [126, 66, 144, 284],\n",
       " [126, 66, 144, 284, 7],\n",
       " [126, 66, 144, 284, 7, 285],\n",
       " [126, 66, 144, 284, 7, 285, 286],\n",
       " [126, 66, 144, 284, 7, 285, 286, 26],\n",
       " [126, 66, 144, 284, 7, 285, 286, 26, 20],\n",
       " [126, 66, 144, 284, 7, 285, 286, 26, 20, 28],\n",
       " [126, 66, 144, 284, 7, 285, 286, 26, 20, 28, 123],\n",
       " [282, 39],\n",
       " [282, 39, 95],\n",
       " [282, 39, 95, 6],\n",
       " [282, 39, 95, 6, 508],\n",
       " [282, 39, 95, 6, 508, 118],\n",
       " [31, 1],\n",
       " [31, 1, 287],\n",
       " [31, 1, 287, 2],\n",
       " [31, 1, 287, 2, 509],\n",
       " [31, 1, 287, 2, 509, 6],\n",
       " [31, 1, 287, 2, 509, 6, 510],\n",
       " [31, 1, 287, 2, 509, 6, 510, 511],\n",
       " [31, 1, 287, 2, 509, 6, 510, 511, 13],\n",
       " [31, 1, 287, 2, 509, 6, 510, 511, 13, 288],\n",
       " [512, 289],\n",
       " [512, 289, 2],\n",
       " [512, 289, 2, 70],\n",
       " [512, 289, 2, 70, 26],\n",
       " [512, 289, 2, 70, 26, 513],\n",
       " [512, 289, 2, 70, 26, 513, 222],\n",
       " [275, 514],\n",
       " [275, 514, 19],\n",
       " [275, 514, 19, 290],\n",
       " [275, 514, 19, 290, 100],\n",
       " [275, 514, 19, 290, 100, 11],\n",
       " [275, 514, 19, 290, 100, 11, 515],\n",
       " [275, 514, 19, 290, 100, 11, 515, 516],\n",
       " [80, 39],\n",
       " [80, 39, 6],\n",
       " [80, 39, 6, 517],\n",
       " [177, 1],\n",
       " [177, 1, 62],\n",
       " [177, 1, 62, 28],\n",
       " [177, 1, 62, 28, 518],\n",
       " [177, 1, 62, 28, 518, 7],\n",
       " [177, 1, 62, 28, 518, 7, 519],\n",
       " [177, 1, 62, 28, 518, 7, 519, 1],\n",
       " [177, 1, 62, 28, 518, 7, 519, 1, 20],\n",
       " [177, 1, 62, 28, 518, 7, 519, 1, 20, 520],\n",
       " [177, 1, 62, 28, 518, 7, 519, 1, 20, 520, 24],\n",
       " [177, 1, 62, 28, 518, 7, 519, 1, 20, 520, 24, 139],\n",
       " [187, 32],\n",
       " [187, 32, 521],\n",
       " [187, 32, 521, 522],\n",
       " [187, 32, 521, 522, 7],\n",
       " [187, 32, 521, 522, 7, 523],\n",
       " [187, 32, 521, 522, 7, 523, 524],\n",
       " [187, 32, 521, 522, 7, 523, 524, 525],\n",
       " [1, 146],\n",
       " [1, 146, 188],\n",
       " [1, 146, 188, 4],\n",
       " [1, 146, 188, 4, 189],\n",
       " [1, 146, 188, 4, 189, 526],\n",
       " [39, 32],\n",
       " [39, 32, 527],\n",
       " [39, 32, 527, 528],\n",
       " [272, 28],\n",
       " [272, 28, 529],\n",
       " [272, 28, 529, 530],\n",
       " [272, 28, 529, 530, 7],\n",
       " [272, 28, 529, 530, 7, 177],\n",
       " [272, 28, 529, 530, 7, 177, 114],\n",
       " [272, 28, 529, 530, 7, 177, 114, 288],\n",
       " [291, 70],\n",
       " [291, 70, 71],\n",
       " [291, 70, 71, 7],\n",
       " [291, 70, 71, 7, 292],\n",
       " [183, 5],\n",
       " [183, 5, 59],\n",
       " [183, 5, 59, 531],\n",
       " [183, 5, 59, 531, 24],\n",
       " [183, 5, 59, 531, 24, 293],\n",
       " [183, 5, 59, 531, 24, 293, 532],\n",
       " [262, 533],\n",
       " [262, 533, 36],\n",
       " [262, 533, 36, 3],\n",
       " [262, 533, 36, 3, 67],\n",
       " [262, 533, 36, 3, 67, 10],\n",
       " [262, 533, 36, 3, 67, 10, 11],\n",
       " [262, 533, 36, 3, 67, 10, 11, 294],\n",
       " [61, 31],\n",
       " [61, 31, 1],\n",
       " [61, 31, 1, 287],\n",
       " [61, 31, 1, 287, 2],\n",
       " [61, 31, 1, 287, 2, 534],\n",
       " [61, 31, 1, 287, 2, 534, 37],\n",
       " [61, 31, 1, 287, 2, 534, 37, 535],\n",
       " [61, 31, 1, 287, 2, 534, 37, 535, 536],\n",
       " [61, 31, 1, 287, 2, 534, 37, 535, 536, 295],\n",
       " [181, 42],\n",
       " [181, 42, 41],\n",
       " [181, 42, 41, 537],\n",
       " [181, 42, 41, 537, 5],\n",
       " [181, 42, 41, 537, 5, 37],\n",
       " [181, 42, 41, 537, 5, 37, 538],\n",
       " [539, 2],\n",
       " [539, 2, 540],\n",
       " [539, 2, 540, 541],\n",
       " [296, 62],\n",
       " [296, 62, 26],\n",
       " [296, 62, 26, 28],\n",
       " [296, 62, 26, 28, 542],\n",
       " [7, 10],\n",
       " [7, 10, 4],\n",
       " [7, 10, 4, 543],\n",
       " [7, 10, 4, 543, 297],\n",
       " [7, 10, 4, 543, 297, 2],\n",
       " [7, 10, 4, 543, 297, 2, 172],\n",
       " [7, 10, 4, 543, 297, 2, 172, 1],\n",
       " [15, 67],\n",
       " [15, 67, 544],\n",
       " [15, 67, 544, 545],\n",
       " [15, 67, 544, 545, 20],\n",
       " [15, 67, 544, 545, 20, 21],\n",
       " [15, 67, 544, 545, 20, 21, 24],\n",
       " [1, 546],\n",
       " [1, 546, 141],\n",
       " [1, 546, 141, 51],\n",
       " [1, 546, 141, 51, 547],\n",
       " [1, 546, 141, 51, 547, 2],\n",
       " [1, 546, 141, 51, 547, 2, 24],\n",
       " [1, 546, 141, 51, 547, 2, 24, 548],\n",
       " [187, 549],\n",
       " [187, 549, 13],\n",
       " [187, 549, 13, 64],\n",
       " [187, 549, 13, 64, 68],\n",
       " [187, 549, 13, 64, 68, 49],\n",
       " [7, 99],\n",
       " [7, 99, 264],\n",
       " [7, 99, 264, 39],\n",
       " [7, 99, 264, 39, 65],\n",
       " [7, 99, 264, 39, 65, 270],\n",
       " [7, 99, 264, 39, 65, 270, 43],\n",
       " [7, 99, 264, 39, 65, 270, 43, 9],\n",
       " [7, 99, 264, 39, 65, 270, 43, 9, 6],\n",
       " [7, 99, 264, 39, 65, 270, 43, 9, 6, 268],\n",
       " [61, 15],\n",
       " [61, 15, 125],\n",
       " [61, 15, 125, 9],\n",
       " [61, 15, 125, 9, 298],\n",
       " [61, 15, 125, 9, 298, 6],\n",
       " [61, 15, 125, 9, 298, 6, 63],\n",
       " [61, 15, 125, 9, 298, 6, 63, 550],\n",
       " [61, 15, 125, 9, 298, 6, 63, 550, 27],\n",
       " [61, 15, 125, 9, 298, 6, 63, 550, 27, 248],\n",
       " [70, 26],\n",
       " [70, 26, 551],\n",
       " [70, 26, 551, 257],\n",
       " [70, 26, 551, 257, 146],\n",
       " [70, 26, 551, 257, 146, 190],\n",
       " [70, 26, 551, 257, 146, 190, 66],\n",
       " [70, 26, 551, 257, 146, 190, 66, 552],\n",
       " [70, 26, 551, 257, 146, 190, 66, 552, 5],\n",
       " [70, 26, 551, 257, 146, 190, 66, 552, 5, 20],\n",
       " [126, 59],\n",
       " [126, 59, 6],\n",
       " [126, 59, 6, 553],\n",
       " [126, 59, 6, 553, 554],\n",
       " [126, 59, 6, 553, 554, 281],\n",
       " [126, 59, 6, 553, 554, 281, 101],\n",
       " [126, 59, 6, 553, 554, 281, 101, 93],\n",
       " [126, 59, 6, 553, 554, 281, 101, 93, 20],\n",
       " [35, 271],\n",
       " [35, 271, 555],\n",
       " [35, 271, 555, 1],\n",
       " [35, 271, 555, 1, 71],\n",
       " [35, 271, 555, 1, 71, 556],\n",
       " [35, 271, 555, 1, 71, 556, 557],\n",
       " [35, 271, 555, 1, 71, 556, 557, 558],\n",
       " [7, 31],\n",
       " [7, 31, 289],\n",
       " [7, 31, 289, 2],\n",
       " [7, 31, 289, 2, 559],\n",
       " [7, 31, 289, 2, 559, 560],\n",
       " [7, 31, 289, 2, 559, 560, 15],\n",
       " [7, 31, 289, 2, 559, 560, 15, 561],\n",
       " [94, 12],\n",
       " [94, 12, 191],\n",
       " [94, 12, 191, 102],\n",
       " [94, 12, 191, 102, 192],\n",
       " [187, 1],\n",
       " [187, 1, 99],\n",
       " [187, 1, 99, 39],\n",
       " [187, 1, 99, 39, 191],\n",
       " [187, 1, 99, 39, 191, 102],\n",
       " [187, 1, 99, 39, 191, 102, 192],\n",
       " [291, 562],\n",
       " [291, 562, 563],\n",
       " [291, 562, 563, 564],\n",
       " [291, 562, 563, 564, 18],\n",
       " [291, 562, 563, 564, 18, 191],\n",
       " [291, 562, 563, 564, 18, 191, 102],\n",
       " [291, 562, 563, 564, 18, 191, 102, 192],\n",
       " [565, 3],\n",
       " [565, 3, 64],\n",
       " [565, 3, 64, 10],\n",
       " [565, 3, 64, 10, 6],\n",
       " [565, 3, 64, 10, 6, 566],\n",
       " [565, 3, 64, 10, 6, 566, 567],\n",
       " [565, 3, 64, 10, 6, 566, 567, 180],\n",
       " [181, 568],\n",
       " [181, 568, 24],\n",
       " [181, 568, 24, 17],\n",
       " [61, 31],\n",
       " [61, 31, 1],\n",
       " [61, 31, 1, 141],\n",
       " [61, 31, 1, 141, 17],\n",
       " [61, 31, 1, 141, 17, 569],\n",
       " [185, 15],\n",
       " [185, 15, 570],\n",
       " [185, 15, 570, 147],\n",
       " [185, 15, 570, 147, 299],\n",
       " [185, 15, 570, 147, 299, 571],\n",
       " [7, 572],\n",
       " [7, 572, 42],\n",
       " ...]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzbvUUQCXPU",
    "outputId": "6d1c961e-8555-43a7-f219-b4cd73fef12d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = max([len(x) for x in input_sequences])\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "9oPMoWBSD1_U"
   },
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "padded_input_sequences = pad_sequences(input_sequences, maxlen = max_len, padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "miRb-QZyIi7_",
    "outputId": "bc41553f-3779-4ae4-a9f0-8cd25b5a79fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,   0,  49, 221],\n",
       "       [  0,   0,   0, ...,  49, 221, 222],\n",
       "       [  0,   0,   0, ..., 221, 222, 113],\n",
       "       ...,\n",
       "       [  0,   0,   0, ..., 107, 108,   5],\n",
       "       [  0,   0,   0, ..., 108,   5,  52],\n",
       "       [  0,   0,   0, ...,   5,  52,  36]], dtype=int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_input_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "qVI0-UUrIsd3"
   },
   "outputs": [],
   "source": [
    "X = padded_input_sequences[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "lXrYHTDFI3uE"
   },
   "outputs": [],
   "source": [
    "y = padded_input_sequences[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kmsFnHx1Qdow",
    "outputId": "517344d5-62bb-4d9f-fe8b-41fdbf03d7b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2635, 18)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-wyYqYgZSeck",
    "outputId": "1d658311-9be0-4810-b743-4a9e0714f4fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2635,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "savskvJPZ7dw",
    "outputId": "01d0d9d4-b909-4245-9eea-7d0756da312b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2635"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = y.shape[0]\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d_L4yko1aBxX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ImkKpc-ZzAb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5OL3vrEXSs_s"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "rs1NPitwSgzk"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y = to_categorical(y,num_classes=l+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iQMJ0I6xSiZf",
    "outputId": "520a1d48-7cbc-4da8-aa5a-287d28fbc26e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2635, 2636)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "9kVeTvR2S8Fk"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "id": "wo-OYfHpTK2o",
    "outputId": "075ba380-33ae-41ea-fd52-43625ca048f0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mukul-barhate/myenv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(l+1, 100, input_length=19))\n",
    "model.add(LSTM(150))\n",
    "model.add(Dense(l+1, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "id": "-GGjqh7ue_Yq",
    "outputId": "2f14d88c-2d85-48d3-81a5-0c5b365541ab"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OxxXkrSXfIBv",
    "outputId": "d809aa2b-600f-4549-cfc1-1dfd1fef1a27"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
       "\n",
       " embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)            ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n",
       "\n",
       " lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                      ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n",
       "\n",
       " dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " embedding (\u001b[38;5;33mEmbedding\u001b[0m)            ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n",
       "\n",
       " lstm (\u001b[38;5;33mLSTM\u001b[0m)                      ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n",
       "\n",
       " dense (\u001b[38;5;33mDense\u001b[0m)                    ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LpFUCALCfJRR",
    "outputId": "96d67a78-3c2e-4462-b2a8-2655c303af8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 16:06:08.149745: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 27783440 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 47ms/step - accuracy: 0.0243 - loss: 7.2284\n",
      "Epoch 2/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 0.0460 - loss: 5.8786\n",
      "Epoch 3/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.0517 - loss: 5.6642\n",
      "Epoch 4/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.0486 - loss: 5.5537\n",
      "Epoch 5/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.0552 - loss: 5.4430\n",
      "Epoch 6/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.0718 - loss: 5.3080\n",
      "Epoch 7/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.0899 - loss: 5.1619\n",
      "Epoch 8/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.0856 - loss: 5.1122\n",
      "Epoch 9/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.1018 - loss: 4.9723\n",
      "Epoch 10/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.1138 - loss: 4.8665\n",
      "Epoch 11/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.1103 - loss: 4.7896\n",
      "Epoch 12/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.1267 - loss: 4.6637\n",
      "Epoch 13/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.1335 - loss: 4.6065\n",
      "Epoch 14/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.1558 - loss: 4.4079\n",
      "Epoch 15/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.1509 - loss: 4.3670\n",
      "Epoch 16/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.1667 - loss: 4.2242\n",
      "Epoch 17/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.1922 - loss: 4.0796\n",
      "Epoch 18/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.2028 - loss: 4.0029\n",
      "Epoch 19/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.2211 - loss: 3.8565\n",
      "Epoch 20/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.2416 - loss: 3.7844\n",
      "Epoch 21/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.2414 - loss: 3.6581\n",
      "Epoch 22/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.2725 - loss: 3.5095\n",
      "Epoch 23/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.2728 - loss: 3.4226\n",
      "Epoch 24/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.2995 - loss: 3.3490\n",
      "Epoch 25/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.2946 - loss: 3.2645\n",
      "Epoch 26/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.3120 - loss: 3.1681\n",
      "Epoch 27/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.3458 - loss: 3.0280\n",
      "Epoch 28/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.3563 - loss: 2.8803\n",
      "Epoch 29/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.3596 - loss: 2.8621\n",
      "Epoch 30/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.4093 - loss: 2.6600\n",
      "Epoch 31/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.4019 - loss: 2.6701\n",
      "Epoch 32/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.4328 - loss: 2.5302\n",
      "Epoch 33/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.4479 - loss: 2.4530\n",
      "Epoch 34/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.4729 - loss: 2.3697\n",
      "Epoch 35/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.5047 - loss: 2.2633\n",
      "Epoch 36/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.4931 - loss: 2.2140\n",
      "Epoch 37/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.5398 - loss: 2.0909\n",
      "Epoch 38/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.5572 - loss: 2.0386\n",
      "Epoch 39/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.5773 - loss: 1.9444\n",
      "Epoch 40/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.5866 - loss: 1.8553\n",
      "Epoch 41/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6108 - loss: 1.8005\n",
      "Epoch 42/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.6021 - loss: 1.7868\n",
      "Epoch 43/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6355 - loss: 1.6445\n",
      "Epoch 44/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6502 - loss: 1.6193\n",
      "Epoch 45/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6775 - loss: 1.5161\n",
      "Epoch 46/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.6676 - loss: 1.4955\n",
      "Epoch 47/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6839 - loss: 1.4488\n",
      "Epoch 48/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6890 - loss: 1.4498\n",
      "Epoch 49/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 56ms/step - accuracy: 0.7230 - loss: 1.3181\n",
      "Epoch 50/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.7245 - loss: 1.2884\n",
      "Epoch 51/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 0.7265 - loss: 1.2575\n",
      "Epoch 52/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - accuracy: 0.7347 - loss: 1.2380\n",
      "Epoch 53/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 46ms/step - accuracy: 0.7540 - loss: 1.1626\n",
      "Epoch 54/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.7530 - loss: 1.1344\n",
      "Epoch 55/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 0.7694 - loss: 1.0899\n",
      "Epoch 56/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.7638 - loss: 1.0886\n",
      "Epoch 57/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - accuracy: 0.7695 - loss: 1.0119\n",
      "Epoch 58/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 0.7912 - loss: 0.9739\n",
      "Epoch 59/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 0.7907 - loss: 0.9904\n",
      "Epoch 60/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 0.8010 - loss: 0.9333\n",
      "Epoch 61/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 46ms/step - accuracy: 0.7986 - loss: 0.9095\n",
      "Epoch 62/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.7961 - loss: 0.9152\n",
      "Epoch 63/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 0.8010 - loss: 0.8894\n",
      "Epoch 64/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 0.8168 - loss: 0.8116\n",
      "Epoch 65/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 47ms/step - accuracy: 0.8078 - loss: 0.8560\n",
      "Epoch 66/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 0.8235 - loss: 0.7639\n",
      "Epoch 67/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.8306 - loss: 0.7761\n",
      "Epoch 68/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.8320 - loss: 0.7470\n",
      "Epoch 69/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 46ms/step - accuracy: 0.8305 - loss: 0.7305\n",
      "Epoch 70/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.8370 - loss: 0.7257\n",
      "Epoch 71/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 0.8430 - loss: 0.7037\n",
      "Epoch 72/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.8368 - loss: 0.6957\n",
      "Epoch 73/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 46ms/step - accuracy: 0.8365 - loss: 0.6891\n",
      "Epoch 74/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 0.8650 - loss: 0.6113\n",
      "Epoch 75/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.8470 - loss: 0.6591\n",
      "Epoch 76/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.8406 - loss: 0.6514\n",
      "Epoch 77/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 47ms/step - accuracy: 0.8496 - loss: 0.5982\n",
      "Epoch 78/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.8565 - loss: 0.5935\n",
      "Epoch 79/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 53ms/step - accuracy: 0.8513 - loss: 0.5852\n",
      "Epoch 80/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - accuracy: 0.8492 - loss: 0.5742\n",
      "Epoch 81/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - accuracy: 0.8646 - loss: 0.5419\n",
      "Epoch 82/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 0.8617 - loss: 0.5396\n",
      "Epoch 83/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.8664 - loss: 0.5211\n",
      "Epoch 84/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 0.8485 - loss: 0.5395\n",
      "Epoch 85/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - accuracy: 0.8672 - loss: 0.4950\n",
      "Epoch 86/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.8684 - loss: 0.5082\n",
      "Epoch 87/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 0.8652 - loss: 0.4969\n",
      "Epoch 88/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8458 - loss: 0.5159\n",
      "Epoch 89/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 46ms/step - accuracy: 0.8675 - loss: 0.4860\n",
      "Epoch 90/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 47ms/step - accuracy: 0.8711 - loss: 0.4737\n",
      "Epoch 91/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 46ms/step - accuracy: 0.8727 - loss: 0.4622\n",
      "Epoch 92/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 0.8589 - loss: 0.4569\n",
      "Epoch 93/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 46ms/step - accuracy: 0.8675 - loss: 0.4587\n",
      "Epoch 94/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - accuracy: 0.8649 - loss: 0.4524\n",
      "Epoch 95/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 46ms/step - accuracy: 0.8628 - loss: 0.4378\n",
      "Epoch 96/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - accuracy: 0.8678 - loss: 0.4344\n",
      "Epoch 97/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - accuracy: 0.8674 - loss: 0.4279\n",
      "Epoch 98/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 68ms/step - accuracy: 0.8639 - loss: 0.4386\n",
      "Epoch 99/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.8652 - loss: 0.4350\n",
      "Epoch 100/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 52ms/step - accuracy: 0.8614 - loss: 0.4286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7048e8e8d220>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the prediction function\n",
    "# def predict_next_words(model, tokenizer, text, num_words=3):\n",
    "#     for _ in range(num_words):\n",
    "#         sequence = tokenizer.texts_to_sequences([text])[0]\n",
    "#         sequence = pad_sequences([sequence], maxlen=19-1, padding='pre')\n",
    "#         predicted = np.argmax(model.predict(sequence), axis=-1)\n",
    "#         output_word = \"\"\n",
    "#         for word, index in tokenizer.word_index.items():\n",
    "#             if index == predicted:\n",
    "#                 output_word = word\n",
    "#                 break\n",
    "#         text += \" \" + output_word\n",
    "#     return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpredict_next_words\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhow are\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[23], line 6\u001b[0m, in \u001b[0;36mpredict_next_words\u001b[0;34m(model, tokenizer, text, num_words)\u001b[0m\n\u001b[1;32m      4\u001b[0m sequence \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mtexts_to_sequences([text])[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      5\u001b[0m sequence \u001b[38;5;241m=\u001b[39m pad_sequences([sequence], maxlen\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m19\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpre\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m predicted \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39margmax(model\u001b[38;5;241m.\u001b[39mpredict(sequence), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      7\u001b[0m output_word \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word, index \u001b[38;5;129;01min\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mword_index\u001b[38;5;241m.\u001b[39mitems():\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# predict_next_words(model, tokenizer,\"how are\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PGeYGwCMfTus",
    "outputId": "2d508555-b83e-470e-e7e5-1b5c10cce70b"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicted_words(model, tokenizer, text, num_words=3):\n",
    "    for _ in range(num_words):\n",
    "        sequence = tokenizer.texts_to_sequences([text])[0]\n",
    "        sequence = pad_sequences([sequence], maxlen=max_len - 1, padding='pre')\n",
    "        predictions = model.predict(sequence, verbose=0)[0]\n",
    "        top_3_indices = np.argsort(predictions)[-3:][::-1]\n",
    "        output_words = [word for word, index in tokenizer.word_index.items() if index in top_3_indices]\n",
    "        \n",
    "        print(f\"Current text: '{text}'\")\n",
    "        print(\"Next word choices:\")\n",
    "        for i, word in enumerate(output_words, 1):\n",
    "            print(f\"  Choice {i}: {text} {word}\")\n",
    "        print()\n",
    "        \n",
    "        # Here we choose the first word from the top 3 for the next iteration (for simplicity)\n",
    "        text += \" \" + output_words[0]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current text: 'how are'\n",
      "Next word choices:\n",
      "  Choice 1: how are here\n",
      "  Choice 2: how are i've\n",
      "  Choice 3: how are not\n",
      "\n",
      "Current text: 'how are here'\n",
      "Next word choices:\n",
      "  Choice 1: how are here to\n",
      "  Choice 2: how are here for\n",
      "  Choice 3: how are here you've\n",
      "\n",
      "Current text: 'how are here to'\n",
      "Next word choices:\n",
      "  Choice 1: how are here to the\n",
      "  Choice 2: how are here to see\n",
      "  Choice 3: how are here to assist\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'how are here to the'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_words(model, tokenizer , \"how are\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'you': 1,\n",
       " 'to': 2,\n",
       " 'we': 3,\n",
       " 'the': 4,\n",
       " 'for': 5,\n",
       " 'a': 6,\n",
       " 'i': 7,\n",
       " 'and': 8,\n",
       " 'of': 9,\n",
       " 'have': 10,\n",
       " 'our': 11,\n",
       " 'your': 12,\n",
       " 'this': 13,\n",
       " 'thank': 14,\n",
       " \"i'm\": 15,\n",
       " 'with': 16,\n",
       " 'in': 17,\n",
       " 'is': 18,\n",
       " \"let's\": 19,\n",
       " 'it': 20,\n",
       " 'on': 21,\n",
       " 'will': 22,\n",
       " 'can': 23,\n",
       " 'me': 24,\n",
       " 'are': 25,\n",
       " 'about': 26,\n",
       " 'any': 27,\n",
       " 'that': 28,\n",
       " 'today': 29,\n",
       " 'please': 30,\n",
       " 'do': 31,\n",
       " 'my': 32,\n",
       " 'topic': 33,\n",
       " 'us': 34,\n",
       " 'or': 35,\n",
       " 'here': 36,\n",
       " 'some': 37,\n",
       " 'welcome': 38,\n",
       " \"it's\": 39,\n",
       " 'name': 40,\n",
       " 'been': 41,\n",
       " \"i've\": 42,\n",
       " 'out': 43,\n",
       " 'take': 44,\n",
       " 'course': 45,\n",
       " 'work': 46,\n",
       " 'event': 47,\n",
       " 'key': 48,\n",
       " 'good': 49,\n",
       " 'time': 50,\n",
       " 'what': 51,\n",
       " 'being': 52,\n",
       " 'am': 53,\n",
       " 'one': 54,\n",
       " 'help': 55,\n",
       " 'point': 56,\n",
       " 'field': 57,\n",
       " 'there': 58,\n",
       " 'not': 59,\n",
       " 'discuss': 60,\n",
       " 'hey': 61,\n",
       " 'see': 62,\n",
       " 'new': 63,\n",
       " 'should': 64,\n",
       " 'like': 65,\n",
       " 'an': 66,\n",
       " 'all': 67,\n",
       " 'be': 68,\n",
       " 'questions': 69,\n",
       " 'how': 70,\n",
       " 'could': 71,\n",
       " 'interested': 72,\n",
       " 'research': 73,\n",
       " 'academic': 74,\n",
       " 'success': 75,\n",
       " 'think': 76,\n",
       " 'feel': 77,\n",
       " 'as': 78,\n",
       " 'so': 79,\n",
       " 'great': 80,\n",
       " 'session': 81,\n",
       " 'start': 82,\n",
       " 'important': 83,\n",
       " 'would': 84,\n",
       " 'workshop': 85,\n",
       " 'subtopic': 86,\n",
       " 'was': 87,\n",
       " 'need': 88,\n",
       " 'insights': 89,\n",
       " 'opportunities': 90,\n",
       " 'provide': 91,\n",
       " 'sure': 92,\n",
       " 'into': 93,\n",
       " \"what's\": 94,\n",
       " 'definitely': 95,\n",
       " 'trip': 96,\n",
       " 'next': 97,\n",
       " 'if': 98,\n",
       " 'know': 99,\n",
       " 'at': 100,\n",
       " 'look': 101,\n",
       " 'pleasure': 102,\n",
       " 'by': 103,\n",
       " 'consider': 104,\n",
       " 'example': 105,\n",
       " 'free': 106,\n",
       " 'once': 107,\n",
       " 'again': 108,\n",
       " 'continue': 109,\n",
       " 'now': 110,\n",
       " 'hope': 111,\n",
       " 'also': 112,\n",
       " 'evening': 113,\n",
       " 'last': 114,\n",
       " 'question': 115,\n",
       " 'concept': 116,\n",
       " 'having': 117,\n",
       " 'issue': 118,\n",
       " 'resources': 119,\n",
       " 'struggling': 120,\n",
       " 'advice': 121,\n",
       " 'hard': 122,\n",
       " 'way': 123,\n",
       " 'subject': 124,\n",
       " 'thinking': 125,\n",
       " \"that's\": 126,\n",
       " 'talk': 127,\n",
       " 'skills': 128,\n",
       " 'study': 129,\n",
       " 'after': 130,\n",
       " 'go': 131,\n",
       " 'together': 132,\n",
       " 'feedback': 133,\n",
       " 'support': 134,\n",
       " 'appreciate': 135,\n",
       " 'dedication': 136,\n",
       " 'reach': 137,\n",
       " 'long': 138,\n",
       " 'up': 139,\n",
       " 'recent': 140,\n",
       " 'believe': 141,\n",
       " 'just': 142,\n",
       " 'make': 143,\n",
       " 'interesting': 144,\n",
       " 'enjoy': 145,\n",
       " 'always': 146,\n",
       " 'but': 147,\n",
       " 'ask': 148,\n",
       " 'everyone': 149,\n",
       " \"today's\": 150,\n",
       " 'begin': 151,\n",
       " 'attention': 152,\n",
       " 'encourage': 153,\n",
       " 'opportunity': 154,\n",
       " 'break': 155,\n",
       " 'goal': 156,\n",
       " 'exercise': 157,\n",
       " 'university': 158,\n",
       " 'graduates': 159,\n",
       " 'hello': 160,\n",
       " 'assignment': 161,\n",
       " 'specific': 162,\n",
       " 'learning': 163,\n",
       " 'more': 164,\n",
       " 'recommend': 165,\n",
       " 'tips': 166,\n",
       " 'considering': 167,\n",
       " 'career': 168,\n",
       " 'guidance': 169,\n",
       " 'potential': 170,\n",
       " 'joining': 171,\n",
       " 'tell': 172,\n",
       " 'implications': 173,\n",
       " 'environment': 174,\n",
       " 'aspect': 175,\n",
       " 'inspiring': 176,\n",
       " 'did': 177,\n",
       " 'plans': 178,\n",
       " 'another': 179,\n",
       " 'soon': 180,\n",
       " 'absolutely': 181,\n",
       " 'mind': 182,\n",
       " 'thanks': 183,\n",
       " 'helps': 184,\n",
       " 'hmm': 185,\n",
       " 'possible': 186,\n",
       " 'oh': 187,\n",
       " 'find': 188,\n",
       " 'best': 189,\n",
       " 'had': 190,\n",
       " 'guilty': 191,\n",
       " 'song': 192,\n",
       " 'lecture': 193,\n",
       " 'orientation': 194,\n",
       " 'excited': 195,\n",
       " 'share': 196,\n",
       " 'cover': 197,\n",
       " '1': 198,\n",
       " '2': 199,\n",
       " 'fact': 200,\n",
       " 'conclusion': 201,\n",
       " 'summary': 202,\n",
       " 'covered': 203,\n",
       " 'findings': 204,\n",
       " 'many': 205,\n",
       " 'keynote': 206,\n",
       " 'speaker': 207,\n",
       " 'join': 208,\n",
       " 'sessions': 209,\n",
       " 'short': 210,\n",
       " 'minutes': 211,\n",
       " 'warm': 212,\n",
       " 'moment': 213,\n",
       " 'special': 214,\n",
       " 'overview': 215,\n",
       " 'forward': 216,\n",
       " 'future': 217,\n",
       " 'occasion': 218,\n",
       " 'their': 219,\n",
       " 'these': 220,\n",
       " 'morning': 221,\n",
       " 'afternoon': 222,\n",
       " 'professor': 223,\n",
       " 'trouble': 224,\n",
       " 'understanding': 225,\n",
       " 'clarification': 226,\n",
       " 'exam': 227,\n",
       " 'coursework': 228,\n",
       " 'recommendations': 229,\n",
       " 'extracurricular': 230,\n",
       " 'activities': 231,\n",
       " 'manage': 232,\n",
       " 'feeling': 233,\n",
       " 'conflict': 234,\n",
       " 'area': 235,\n",
       " 'applying': 236,\n",
       " 'graduate': 237,\n",
       " 'application': 238,\n",
       " 'process': 239,\n",
       " 'writing': 240,\n",
       " 'personal': 241,\n",
       " 'pursue': 242,\n",
       " 'graduation': 243,\n",
       " 'syllabus': 244,\n",
       " 'looking': 245,\n",
       " 'workshops': 246,\n",
       " 'materials': 247,\n",
       " 'suggestions': 248,\n",
       " 'improvement': 249,\n",
       " 'planning': 250,\n",
       " 'studies': 251,\n",
       " 'applications': 252,\n",
       " 'supportive': 253,\n",
       " \"students'\": 254,\n",
       " 'fortunate': 255,\n",
       " 'grateful': 256,\n",
       " \"you've\": 257,\n",
       " 'positive': 258,\n",
       " 'impact': 259,\n",
       " 'education': 260,\n",
       " 'life': 261,\n",
       " 'no': 262,\n",
       " 'hear': 263,\n",
       " 'right': 264,\n",
       " 'current': 265,\n",
       " 'lately': 266,\n",
       " 'finished': 267,\n",
       " 'movie': 268,\n",
       " 'title': 269,\n",
       " 'something': 270,\n",
       " 'maybe': 271,\n",
       " 'remember': 272,\n",
       " 'plan': 273,\n",
       " 'road': 274,\n",
       " 'sounds': 275,\n",
       " 'really': 276,\n",
       " 'anytime': 277,\n",
       " 'back': 278,\n",
       " 'read': 279,\n",
       " 'book': 280,\n",
       " \"i'll\": 281,\n",
       " 'yeah': 282,\n",
       " 'following': 283,\n",
       " 'perspective': 284,\n",
       " \"hadn't\": 285,\n",
       " 'thought': 286,\n",
       " 'want': 287,\n",
       " 'week': 288,\n",
       " 'love': 289,\n",
       " 'meet': 290,\n",
       " 'haha': 291,\n",
       " 'forget': 292,\n",
       " 'too': 293,\n",
       " 'moments': 294,\n",
       " 'later': 295,\n",
       " \"we'll\": 296,\n",
       " 'story': 297,\n",
       " 'starting': 298,\n",
       " 'open': 299,\n",
       " 'experiences': 300,\n",
       " \"you're\": 301,\n",
       " 'camping': 302,\n",
       " 'families': 303,\n",
       " 'delighted': 304,\n",
       " 'seminar': 305,\n",
       " 'discussing': 306,\n",
       " 'before': 307,\n",
       " 'review': 308,\n",
       " 'focus': 309,\n",
       " 'concepts': 310,\n",
       " 'principles': 311,\n",
       " 'principle': 312,\n",
       " 'illustrate': 313,\n",
       " 'understand': 314,\n",
       " 'examine': 315,\n",
       " 'explanation': 316,\n",
       " 'data': 317,\n",
       " 'according': 318,\n",
       " 'statistic': 319,\n",
       " 'significance': 320,\n",
       " 'critical': 321,\n",
       " 'main': 322,\n",
       " 'points': 323,\n",
       " 'discussed': 324,\n",
       " 'explored': 325,\n",
       " 'conference': 326,\n",
       " 'participating': 327,\n",
       " 'advancements': 328,\n",
       " 'acknowledging': 329,\n",
       " \"speaker's\": 330,\n",
       " \"don't\": 331,\n",
       " 'exciting': 332,\n",
       " 'informative': 333,\n",
       " 'reconvene': 334,\n",
       " 'team': 335,\n",
       " 'insightful': 336,\n",
       " 'practical': 337,\n",
       " 'knowledge': 338,\n",
       " 'introducing': 339,\n",
       " 'them': 340,\n",
       " 'hands': 341,\n",
       " 'participate': 342,\n",
       " 'actively': 343,\n",
       " 'icebreaker': 344,\n",
       " 'introduce': 345,\n",
       " 'move': 346,\n",
       " 'final': 347,\n",
       " '3': 348,\n",
       " 'brief': 349,\n",
       " 'few': 350,\n",
       " 'case': 351,\n",
       " 'from': 352,\n",
       " 'contributions': 353,\n",
       " 'part': 354,\n",
       " 'valuable': 355,\n",
       " 'celebrate': 356,\n",
       " 'collective': 357,\n",
       " 'reflect': 358,\n",
       " 'come': 359,\n",
       " 'achievements': 360,\n",
       " 'challenges': 361,\n",
       " 'proud': 362,\n",
       " 'committed': 363,\n",
       " 'community': 364,\n",
       " 'each': 365,\n",
       " 'every': 366,\n",
       " 'instrumental': 367,\n",
       " 'rest': 368,\n",
       " 'student': 369,\n",
       " 'campus': 370,\n",
       " 'they': 371,\n",
       " 'mr': 372,\n",
       " 'ms': 373,\n",
       " 'meeting': 374,\n",
       " 'homework': 375,\n",
       " 'explain': 376,\n",
       " 'hoping': 377,\n",
       " 'studying': 378,\n",
       " 'upcoming': 379,\n",
       " 'stay': 380,\n",
       " 'organized': 381,\n",
       " 'pursuing': 382,\n",
       " 'balancing': 383,\n",
       " 'schoolwork': 384,\n",
       " 'effectively': 385,\n",
       " 'overwhelmed': 386,\n",
       " 'workload': 387,\n",
       " 'anything': 388,\n",
       " 'stress': 389,\n",
       " 'better': 390,\n",
       " 'schedule': 391,\n",
       " 'reschedule': 392,\n",
       " 'doing': 393,\n",
       " 'undergraduate': 394,\n",
       " 'school': 395,\n",
       " 'difficulty': 396,\n",
       " 'essays': 397,\n",
       " 'exploring': 398,\n",
       " 'internship': 399,\n",
       " 'finding': 400,\n",
       " 'placements': 401,\n",
       " 'affecting': 402,\n",
       " 'performance': 403,\n",
       " 'public': 404,\n",
       " 'speaking': 405,\n",
       " 'presentations': 406,\n",
       " 'improving': 407,\n",
       " 'communication': 408,\n",
       " 'club': 409,\n",
       " 'organization': 410,\n",
       " 'related': 411,\n",
       " 'path': 412,\n",
       " 'counseling': 413,\n",
       " 'passionate': 414,\n",
       " 'incorporate': 415,\n",
       " 'over': 416,\n",
       " 'interests': 417,\n",
       " 'dropping': 418,\n",
       " 'advise': 419,\n",
       " 'alternatives': 420,\n",
       " 'concern': 421,\n",
       " 'classroom': 422,\n",
       " 'improve': 423,\n",
       " 'outside': 424,\n",
       " 'class': 425,\n",
       " 'accessing': 426,\n",
       " 'online': 427,\n",
       " 'troubleshoot': 428,\n",
       " 'scholarships': 429,\n",
       " 'particular': 430,\n",
       " 'additional': 431,\n",
       " 'abroad': 432,\n",
       " 'offer': 433,\n",
       " 'international': 434,\n",
       " 'requirements': 435,\n",
       " 'changing': 436,\n",
       " 'major': 437,\n",
       " 'options': 438,\n",
       " 'group': 439,\n",
       " 'member': 440,\n",
       " 'project': 441,\n",
       " 'resolve': 442,\n",
       " 'teacher': 443,\n",
       " 'challenging': 444,\n",
       " 'critically': 445,\n",
       " 'creatively': 446,\n",
       " 'enthusiasm': 447,\n",
       " 'teaching': 448,\n",
       " 'contagious': 449,\n",
       " 'mentor': 450,\n",
       " 'provided': 451,\n",
       " 'believing': 452,\n",
       " 'encouraging': 453,\n",
       " 'full': 454,\n",
       " 'admire': 455,\n",
       " 'passion': 456,\n",
       " 'expertise': 457,\n",
       " 'invaluable': 458,\n",
       " 'making': 459,\n",
       " \"how's\": 460,\n",
       " 'going': 461,\n",
       " 'missed': 462,\n",
       " 'hanging': 463,\n",
       " 'catch': 464,\n",
       " 'often': 465,\n",
       " 'crazy': 466,\n",
       " \"can't\": 467,\n",
       " 'already': 468,\n",
       " 'month': 469,\n",
       " 'flies': 470,\n",
       " 'watched': 471,\n",
       " 'movies': 472,\n",
       " 'watching': 473,\n",
       " 'amazing': 474,\n",
       " 'tv': 475,\n",
       " 'shows': 476,\n",
       " 'binge': 477,\n",
       " 'watch': 478,\n",
       " 'weekend': 479,\n",
       " 'hiking': 480,\n",
       " 'try': 481,\n",
       " 'restaurant': 482,\n",
       " 'down': 483,\n",
       " 'whatever': 484,\n",
       " 'took': 485,\n",
       " 'summer': 486,\n",
       " 'times': 487,\n",
       " 'where': 488,\n",
       " 'taking': 489,\n",
       " 'blast': 490,\n",
       " 'vent': 491,\n",
       " 'minute': 492,\n",
       " 'stressed': 493,\n",
       " 'sometimes': 494,\n",
       " 'got': 495,\n",
       " 'books': 496,\n",
       " 'recently': 497,\n",
       " 'actually': 498,\n",
       " 'check': 499,\n",
       " \"you'll\": 500,\n",
       " 'aliens': 501,\n",
       " 'universe': 502,\n",
       " 'vast': 503,\n",
       " 'boggling': 504,\n",
       " 'honestly': 505,\n",
       " 'closely': 506,\n",
       " \"here's\": 507,\n",
       " 'complex': 508,\n",
       " 'grab': 509,\n",
       " 'coffee': 510,\n",
       " 'sometime': 511,\n",
       " \"i'd\": 512,\n",
       " 'wednesday': 513,\n",
       " 'perfect': 514,\n",
       " 'usual': 515,\n",
       " 'spot': 516,\n",
       " 'date': 517,\n",
       " 'meme': 518,\n",
       " 'sent': 519,\n",
       " 'cracked': 520,\n",
       " 'gosh': 521,\n",
       " 'yes': 522,\n",
       " \"couldn't\": 523,\n",
       " 'stop': 524,\n",
       " 'laughing': 525,\n",
       " 'memes': 526,\n",
       " 'superpower': 527,\n",
       " '': 528,\n",
       " 'embarrassing': 529,\n",
       " 'thing': 530,\n",
       " 'judging': 531,\n",
       " 'harshly': 532,\n",
       " 'judgment': 533,\n",
       " 'play': 534,\n",
       " 'video': 535,\n",
       " 'games': 536,\n",
       " 'itching': 537,\n",
       " 'gaming': 538,\n",
       " 'prepare': 539,\n",
       " 'get': 540,\n",
       " 'schooled': 541,\n",
       " '': 542,\n",
       " 'craziest': 543,\n",
       " 'ears': 544,\n",
       " 'lay': 545,\n",
       " \"won't\": 546,\n",
       " 'happened': 547,\n",
       " 'yesterday': 548,\n",
       " 'boy': 549,\n",
       " 'hobby': 550,\n",
       " 'photography': 551,\n",
       " 'eye': 552,\n",
       " 'bad': 553,\n",
       " 'idea': 554,\n",
       " 'cooking': 555,\n",
       " 'host': 556,\n",
       " 'dinner': 557,\n",
       " 'parties': 558,\n",
       " 'eat': 559,\n",
       " 'alright': 560,\n",
       " 'sold': 561,\n",
       " 'classic': 562,\n",
       " 'choice': 563,\n",
       " 'mine': 564,\n",
       " 'nice': 565,\n",
       " 'karaoke': 566,\n",
       " 'night': 567,\n",
       " 'count': 568,\n",
       " 'ghosts': 569,\n",
       " 'skeptical': 570,\n",
       " 'minded': 571,\n",
       " 'swear': 572,\n",
       " 'paranormal': 573,\n",
       " 'say': 574,\n",
       " 'seen': 575,\n",
       " 'things': 576,\n",
       " 'wanted': 577,\n",
       " 'ghost': 578,\n",
       " 'hunting': 579,\n",
       " 'game': 580,\n",
       " 'braver': 581,\n",
       " 'than': 582,\n",
       " 'favorite': 583,\n",
       " 'childhood': 584,\n",
       " 'memory': 585,\n",
       " 'probably': 586,\n",
       " 'went': 587,\n",
       " 'much': 588,\n",
       " 'fun': 589,\n",
       " 'miss': 590,\n",
       " 'those': 591,\n",
       " 'days': 592,\n",
       " 'overdue': 593,\n",
       " 'tough': 594,\n",
       " 'considered': 595,\n",
       " 'solution': 596,\n",
       " 'friend': 597,\n",
       " 'figure': 598,\n",
       " 'primary': 599,\n",
       " 'refer': 600,\n",
       " 'distributed': 601,\n",
       " 'several': 602,\n",
       " 'foundational': 603,\n",
       " 'imagine': 604,\n",
       " 'scenario': 605,\n",
       " 'moving': 606,\n",
       " 'further': 607,\n",
       " 'elaborate': 608,\n",
       " 'highlights': 609,\n",
       " 'delve': 610,\n",
       " 'deeper': 611,\n",
       " 'leads': 612,\n",
       " 'recap': 613,\n",
       " 'topics': 614,\n",
       " 'concluded': 615,\n",
       " 'happy': 616,\n",
       " 'answer': 617,\n",
       " 'may': 618,\n",
       " 'annual': 619,\n",
       " 'gather': 620,\n",
       " 'honored': 621,\n",
       " 'welcoming': 622,\n",
       " 'address': 623,\n",
       " 'engage': 624,\n",
       " 'speakers': 625,\n",
       " 'learn': 626,\n",
       " 'network': 627,\n",
       " 'visit': 628,\n",
       " 'poster': 629,\n",
       " 'during': 630,\n",
       " 'breaks': 631,\n",
       " 'projects': 632,\n",
       " 'display': 633,\n",
       " 'attend': 634,\n",
       " 'breakout': 635,\n",
       " 'input': 636,\n",
       " 'highly': 637,\n",
       " 'valued': 638,\n",
       " 'lineup': 639,\n",
       " 'talks': 640,\n",
       " 'panels': 641,\n",
       " 'engaging': 642,\n",
       " '15': 643,\n",
       " 'refreshments': 644,\n",
       " 'most': 645,\n",
       " 'resume': 646,\n",
       " 'program': 647,\n",
       " 'shortly': 648,\n",
       " 'give': 649,\n",
       " 'excellent': 650,\n",
       " 'presentation': 651,\n",
       " 'floor': 652,\n",
       " 'raise': 653,\n",
       " 'hand': 654,\n",
       " 'bring': 655,\n",
       " 'microphone': 656,\n",
       " 'announcement': 657,\n",
       " 'networking': 658,\n",
       " 'reception': 659,\n",
       " 'unwind': 660,\n",
       " 'socialize': 661,\n",
       " 'fantastic': 662,\n",
       " 'experience': 663,\n",
       " 'thrilled': 664,\n",
       " 'focused': 665,\n",
       " 'aim': 666,\n",
       " 'facilitators': 667,\n",
       " \"facilitator's\": 668,\n",
       " 'expert': 669,\n",
       " 'interactive': 670,\n",
       " 'create': 671,\n",
       " 'collaborative': 672,\n",
       " 'quick': 673,\n",
       " 'activity': 674,\n",
       " 'pair': 675,\n",
       " 'someone': 676,\n",
       " 'yourself': 677,\n",
       " 'dive': 678,\n",
       " 'content': 679,\n",
       " 'first': 680,\n",
       " 'plenty': 681,\n",
       " 'practice': 682,\n",
       " 'prepared': 683,\n",
       " 'exercises': 684,\n",
       " '10': 685,\n",
       " 'chance': 686,\n",
       " 'refresh': 687,\n",
       " 'demonstrate': 688,\n",
       " 'takeaways': 689,\n",
       " 'pay': 690,\n",
       " 'close': 691,\n",
       " 'details': 692,\n",
       " 'complete': 693,\n",
       " 'through': 694,\n",
       " 'job': 695,\n",
       " 'subtopics': 696,\n",
       " 'practiced': 697,\n",
       " 'techniques': 698,\n",
       " 'found': 699,\n",
       " 'active': 700,\n",
       " 'participation': 701,\n",
       " 'fill': 702,\n",
       " 'form': 703,\n",
       " 'leave': 704,\n",
       " 'seeing': 705,\n",
       " 'ladies': 706,\n",
       " 'gentlemen': 707,\n",
       " 'achievement': 708,\n",
       " 'testament': 709,\n",
       " 'efforts': 710,\n",
       " 'distinguished': 711,\n",
       " 'guests': 712,\n",
       " 'honoring': 713,\n",
       " 'presence': 714,\n",
       " 'sponsors': 715,\n",
       " 'generous': 716,\n",
       " 'without': 717,\n",
       " 'big': 718,\n",
       " 'organizing': 719,\n",
       " 'made': 720,\n",
       " 'journey': 721,\n",
       " 'since': 722,\n",
       " 'result': 723,\n",
       " 'teamwork': 724,\n",
       " 'perseverance': 725,\n",
       " 'faced': 726,\n",
       " 'overcome': 727,\n",
       " 'stand': 728,\n",
       " 'accomplishments': 729,\n",
       " 'celebration': 730,\n",
       " 'filled': 731,\n",
       " 'optimism': 732,\n",
       " 'initiatives': 733,\n",
       " 'pipeline': 734,\n",
       " 'continuous': 735,\n",
       " 'innovation': 736,\n",
       " 'let': 737,\n",
       " 'towards': 738,\n",
       " 'common': 739,\n",
       " 'goals': 740,\n",
       " 'its': 741,\n",
       " 'transition': 742,\n",
       " 'smoothly': 743,\n",
       " 'college': 744,\n",
       " 'facilities': 745,\n",
       " 'note': 746,\n",
       " 'locations': 747,\n",
       " 'mentioned': 748,\n",
       " 'programs': 749,\n",
       " 'offered': 750,\n",
       " 'advisors': 751,\n",
       " 'assist': 752,\n",
       " 'selection': 753,\n",
       " 'policies': 754,\n",
       " 'procedures': 755,\n",
       " 'essential': 756,\n",
       " 'familiar': 757,\n",
       " 'guidelines': 758,\n",
       " 'tour': 759,\n",
       " 'seek': 760,\n",
       " 'ambassadors': 761,\n",
       " 'helpful': 762,\n",
       " 'leadership': 763,\n",
       " 'dean': 764,\n",
       " 'department': 765,\n",
       " 'introduction': 766,\n",
       " 'faces': 767,\n",
       " 'providing': 768,\n",
       " 'strive': 769,\n",
       " 'excellence': 770,\n",
       " 'growth': 771,\n",
       " 'assistance': 772,\n",
       " 'ceremony': 773,\n",
       " 'tonight': 774,\n",
       " 'momentous': 775,\n",
       " 'extend': 776,\n",
       " 'brought': 777,\n",
       " 'incredibly': 778,\n",
       " 'acknowledge': 779,\n",
       " 'faculty': 780,\n",
       " 'staff': 781,\n",
       " 'unwavering': 782,\n",
       " 'commitment': 783,\n",
       " 'valedictorian': 784,\n",
       " 'speech': 785,\n",
       " 'words': 786,\n",
       " 'wisdom': 787,\n",
       " 'encouragement': 788,\n",
       " 'present': 789,\n",
       " 'degrees': 790,\n",
       " 'called': 791,\n",
       " 'congratulations': 792,\n",
       " 'wish': 793,\n",
       " 'endeavors': 794,\n",
       " 'attending': 795,\n",
       " 'interest': 796,\n",
       " 'importance': 797,\n",
       " 'deepen': 798,\n",
       " 'fundamental': 799,\n",
       " 'grasp': 800,\n",
       " 'explore': 801,\n",
       " 'leverage': 802,\n",
       " 'solutions': 803,\n",
       " 'aspects': 804,\n",
       " 'discussion': 805,\n",
       " 'perspectives': 806,\n",
       " \"we've\": 807,\n",
       " 'engagement': 808,\n",
       " 'continued': 809,\n",
       " 'exploration': 810}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(model,open('modelf.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
